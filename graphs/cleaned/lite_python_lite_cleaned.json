{"python.lite": [], "python.lite.Optimize.__str__": ["<builtin>.str"], "<builtin>.str": [], "python.lite.RepresentativeDataset.__init__": [], "python.lite.TargetSpec.__init__": ["<builtin>.set"], "<builtin>.set": [], "python.lite.QuantizationMode.__init__": ["python.lite.QuantizationMode._validate_int8_required", "absl.logging.warning"], "absl.logging.warning": [], "python.lite.QuantizationMode._validate_int8_required": ["python.lite.RepresentativeDataset.__init__", "python.lite.QuantizationMode._smallest_supported_type", "python.lite.QuantizationMode._is_int8_target_required", "<builtin>.isinstance", "<builtin>.ValueError"], "python.lite.QuantizationMode.post_training_int8_no_float": ["python.lite.QuantizationMode.is_allow_float", "python.lite.QuantizationMode._is_int8_target_required", "python.lite.QuantizationMode.any_optimization_enabled", "python.lite.QuantizationMode._is_int16x8_target_required"], "python.lite.QuantizationMode.any_optimization_enabled": ["<builtin>.bool", "<builtin>.set"], "python.lite.QuantizationMode._is_int8_target_required": ["<builtin>.set"], "python.lite.QuantizationMode._is_int16x8_target_required": ["<builtin>.set"], "python.lite.QuantizationMode.is_allow_float": ["<builtin>.set"], "python.lite.QuantizationMode.post_training_int8_allow_float": ["python.lite.QuantizationMode._is_int16x8_target_required", "python.lite.QuantizationMode.any_optimization_enabled", "python.lite.QuantizationMode._smallest_supported_type"], "python.lite.QuantizationMode._smallest_supported_type": ["<builtin>.min"], "python.lite.QuantizationMode.is_post_training_integer_quantize_8": ["python.lite.QuantizationMode.post_training_int8_no_float", "python.lite.QuantizationMode.post_training_int8_allow_float"], "python.lite.QuantizationMode.is_post_training_integer_quantize_16x8": ["python.lite.QuantizationMode.post_training_int16x8_allow_float", "python.lite.QuantizationMode.post_training_int16x8_no_float"], "python.lite.QuantizationMode.post_training_int16x8_no_float": ["python.lite.QuantizationMode.is_allow_float", "python.lite.QuantizationMode._is_int8_target_required", "python.lite.QuantizationMode.any_optimization_enabled", "python.lite.QuantizationMode._is_int16x8_target_required"], "python.lite.QuantizationMode.post_training_int16x8_allow_float": ["python.lite.QuantizationMode.is_allow_float", "python.lite.QuantizationMode._is_int16x8_target_required", "python.lite.QuantizationMode.any_optimization_enabled"], "python.lite.QuantizationMode.is_post_training_integer_quantize": ["python.lite.QuantizationMode.is_post_training_integer_quantize_8", "python.lite.QuantizationMode.is_post_training_integer_quantize_16x8"], "python.lite.QuantizationMode.is_integer_quantize": ["python.lite.QuantizationMode.is_training_time_int8_allow_float", "python.lite.QuantizationMode.is_post_training_integer_quantize"], "python.lite.QuantizationMode.is_training_time_int8_allow_float": ["python.lite.QuantizationMode.contains_training_quant_op", "python.lite.QuantizationMode.any_optimization_enabled"], "python.lite.QuantizationMode.contains_training_quant_op": ["<builtin>.frozenset"], "python.lite.QuantizationMode.is_bfloat16_inference_allowed": ["python.lite.QuantizationMode._smallest_supported_type", "python.lite.QuantizationMode.any_optimization_enabled"], "python.lite.QuantizationMode.post_training_dynamic_range_int8": ["python.lite.QuantizationMode.contains_training_quant_op", "python.lite.QuantizationMode._smallest_supported_type", "python.lite.QuantizationMode.any_optimization_enabled"], "python.lite.QuantizationMode.post_training_fp16": ["python.lite.QuantizationMode._smallest_supported_type", "python.lite.QuantizationMode.any_optimization_enabled"], "python.lite.QuantizationMode.fp32_execution": ["python.lite.QuantizationMode.is_integer_quantize", "python.lite.QuantizationMode.post_training_dynamic_range_int8", "python.lite.QuantizationMode.post_training_fp16"], "python.lite.QuantizationMode.activations_type": ["python.lite.QuantizationMode.is_integer_quantize", "python.lite.QuantizationMode._is_int16x8_target_required"], "python.lite.QuantizationMode.converter_flags": ["python.lite.QuantizationMode.post_training_dynamic_range_int8", "python.lite.QuantizationMode.post_training_fp16", "python.lite.QuantizationMode.is_bfloat16_inference_allowed", "python.lite.QuantizationMode.is_integer_quantize", "python.lite.QuantizationMode.activations_type"], "<builtin>.ValueError": [], "<builtin>.isinstance": [], "<builtin>.bool": [], "python.lite.QuantizationMode._smallest_supported_type.<lambda1>": [], "<builtin>.min": [], "<builtin>.frozenset": [], "python.lite.TFLiteConverterBase.__init__": ["python.metrics_nonportable.TFLiteConverterMetrics", "python.lite.TargetSpec.__init__", "python.metrics_portable.TFLiteConverterMetrics", "<builtin>.set"], "python.metrics_nonportable.TFLiteConverterMetrics": [], "python.metrics_portable.TFLiteConverterMetrics": [], "python.lite.TFLiteConverterBase._grappler_config": ["python.util.get_grappler_config", "<builtin>.set"], "python.util.get_grappler_config": [], "python.lite.TFLiteConverterBase._quantize": ["python.convert.mlir_quantize", "python.lite.RepresentativeDataset.__init__", "optimize.calibrator.Calibrator", "optimize.calibrator.add_intermediate_tensors", "<builtin>.isinstance"], "optimize.calibrator.add_intermediate_tensors": [], "optimize.calibrator.Calibrator": [], "python.convert.mlir_quantize": [], "python.lite.TFLiteConverterBase._is_unknown_shapes_allowed": [], "python.lite.TFLiteConverterBase._get_base_converter_args": [], "python.lite.TFLiteConverterBase._contains_function_with_implements_attr": [], "python.lite.TFLiteConverterBase._parse_saved_model_args": ["saved_model.loader_impl.parse_saved_model_with_debug_info", "python.lite.TFLiteConverterBase._contains_function_with_implements_attr", "absl.logging.warning", "<builtin>.ValueError"], "saved_model.loader_impl.parse_saved_model_with_debug_info": [], "python.lite.TFLiteConverterBase._sparsify_model": [], "python.lite.TFLiteConverterBase._validate_experimental_new_quantizer_flag": ["<builtin>.ValueError"], "python.lite.TFLiteConverterBase._increase_conversion_attempt_metric": [], "python.lite.TFLiteConverterBase._increase_conversion_success_metric": [], "python.lite.TFLiteConverterBase._save_conversion_params_metric": ["python.lite.TFLiteConverterBase._save_conversion_params_metric.format_param", "python.lite.QuantizationMode.__init__", "python.lite.QuantizationMode.converter_flags", "python.lite.TFLiteConverterBase._get_base_converter_args"], "python.lite.TFLiteConverterBase._save_conversion_params_metric.format_element": ["<builtin>.str", "<builtin>.isinstance", "pprint.pformat"], "pprint.pformat": [], "python.lite.TFLiteConverterBase._save_conversion_params_metric.format_param": ["python.lite.TFLiteConverterBase._save_conversion_params_metric.format_element", "<builtin>.sorted", "<builtin>.isinstance"], "<builtin>.sorted": [], "python.lite.TFLiteConverterBase._set_conversion_latency_metric": [], "python.convert_phase.convert_phase": [], "python.lite.TFLiteConverterBase": ["python.convert_phase.convert_phase"], "python.lite.TFLiteConverterBase._optimize_tflite_model": ["python.lite.QuantizationMode.is_allow_float", "python.lite.QuantizationMode.is_post_training_integer_quantize", "python.convert.mlir_sparsify", "python.lite.TFLiteConverterBase._sparsify_model", "absl.logging.warning", "python.lite.QuantizationMode.is_integer_quantize", "python.lite.TFLiteConverterBase._quantize", "python.convert.deduplicate_readonly_buffers", "python.util.modify_model_io_type", "python.lite.QuantizationMode.activations_type"], "python.util.modify_model_io_type": [], "python.convert.mlir_sparsify": [], "python.convert.deduplicate_readonly_buffers": [], "python.lite.TFLiteConverterBase._convert_and_export_metrics": ["python.lite.TFLiteConverterBase._increase_conversion_attempt_metric", "time.process_time", "python.lite.TFLiteConverterBase._increase_conversion_success_metric", "python.lite.TFLiteConverterBase._save_conversion_params_metric", "python.lite.TFLiteConverterBase._set_conversion_latency_metric", "<builtin>.round"], "time.process_time": [], "<builtin>.round": [], "python.lite._export_metrics": ["functools.wraps"], "functools.wraps": [], "python.lite._export_metrics.wrapper": [], "python.lite.TFLiteConverterBaseV2.__init__": ["<builtin>.super"], "<builtin>.super": [], "python.lite.TFLiteConverterBaseV2._validate_inference_input_output_types": ["python.lite.QuantizationMode.is_integer_quantize", "python.lite.QuantizationMode.is_post_training_integer_quantize_16x8", "<builtin>.ValueError"], "python.lite.TFLiteConverterBaseV2": ["python.convert_phase.convert_phase"], "python.lite.TFLiteConverterBaseV2._load_saved_model": ["saved_model.loader_impl.SavedModelLoader", "framework.ops.Graph"], "framework.ops.Graph": [], "saved_model.loader_impl.SavedModelLoader": [], "python.lite.TFLiteConverterBaseV2._validate_inputs": ["python.lite.TFLiteConverterBaseV2._validate_inference_input_output_types", "python.lite.QuantizationMode.__init__", "python.lite.TFLiteConverterBase._is_unknown_shapes_allowed", "python.util.build_debug_info_func", "python.lite.TFLiteConverterBase._save_conversion_params_metric", "python.util.convert_debug_info_func", "<builtin>.hasattr", "python.util.get_debug_info", "python.lite.TFLiteConverterBase._validate_experimental_new_quantizer_flag", "python.util.get_tensor_name", "<builtin>.ValueError"], "python.util.get_tensor_name": [], "<builtin>.hasattr": [], "python.util.build_debug_info_func": [], "python.util.get_debug_info": [], "python.util.convert_debug_info_func": [], "python.lite.TFLiteConverterBaseV2._optimize_tf_model": ["python.lite.TFLiteConverterBase._grappler_config", "python.util.run_graph_optimizations"], "python.util.run_graph_optimizations": [], "python.lite.TFLiteConverterBaseV2.convert": ["python.lite.TFLiteConverterBaseV2._validate_inputs", "python.convert.toco_convert_impl", "absl.logging.warning", "absl.logging.info", "python.lite.QuantizationMode.converter_flags", "python.lite.TFLiteConverterBase._get_base_converter_args", "python.lite.TFLiteConverterBase._optimize_tflite_model"], "absl.logging.info": [], "python.convert.toco_convert_impl": [], "python.lite.TFLiteSavedModelConverterV2.__init__": ["<builtin>.super", "python.lite.TFLiteConverterBase._parse_saved_model_args"], "python.lite.TFLiteSavedModelConverterV2": ["python.lite._export_metrics"], "python.lite.TFLiteSavedModelConverterV2.convert": ["python.lite.TFLiteConverterBaseV2._load_saved_model", "python.convert_saved_model.freeze_saved_model", "python.lite.TFLiteConverterBaseV2._validate_inference_input_output_types", "python.lite.QuantizationMode.__init__", "python.util.build_debug_info_func", "python.lite.TFLiteConverterBase._save_conversion_params_metric", "<builtin>.super", "python.util.convert_debug_info_func", "python.lite.QuantizationMode.converter_flags", "python.lite.TFLiteConverterBase._get_base_converter_args", "python.convert.convert_saved_model", "python.util.get_debug_info", "python.lite.TFLiteConverterBase._optimize_tflite_model"], "python.convert_saved_model.freeze_saved_model": [], "python.convert.convert_saved_model": [], "python.lite.TFLiteKerasModelConverterV2.__init__": ["<builtin>.super"], "python.lite.TFLiteKerasModelConverterV2": ["python.convert_phase.convert_phase", "python.lite._export_metrics"], "python.lite.TFLiteKerasModelConverterV2._convert_keras_to_saved_model": ["python.lite.TFLiteConverterBaseV2._load_saved_model", "<builtin>.set", "saved_model.save_options.SaveOptions", "python.lite.TFLiteConverterBase._parse_saved_model_args", "saved_model.load.load", "python.saved_model.save"], "saved_model.save_options.SaveOptions": [], "python.saved_model.save": [], "saved_model.load.load": [], "python.lite.TFLiteKerasModelConverterV2._freeze_keras_model": ["framework.convert_to_constants.convert_variables_to_constants_v2_as_graph", "python.util.model_input_signature", "python.util.trace_model_call", "<builtin>.isinstance"], "python.util.model_input_signature": [], "python.util.trace_model_call": [], "framework.convert_to_constants.convert_variables_to_constants_v2_as_graph": [], "python.lite.TFLiteKerasModelConverterV2._convert_as_saved_model": ["<builtin>.super", "shutil.rmtree", "tempfile.mkdtemp", "python.lite.TFLiteKerasModelConverterV2._convert_keras_to_saved_model"], "tempfile.mkdtemp": [], "shutil.rmtree": [], "python.lite.TFLiteKerasModelConverterV2.convert": ["python.lite.TFLiteKerasModelConverterV2._freeze_keras_model", "python.lite.TFLiteConverterBaseV2._optimize_tf_model", "python.lite.TFLiteKerasModelConverterV2._convert_as_saved_model", "<builtin>.super"], "python.lite.TFLiteFrozenGraphConverterV2.__init__": ["<builtin>.super"], "python.lite.TFLiteFrozenGraphConverterV2": ["python.convert_phase.convert_phase", "python.lite._export_metrics"], "python.lite.TFLiteFrozenGraphConverterV2._freeze_concrete_function": ["framework.convert_to_constants.convert_variables_to_constants_v2_as_graph", "<builtin>.len", "<builtin>.ValueError"], "<builtin>.len": [], "python.lite.TFLiteFrozenGraphConverterV2._convert_concrete_functions_to_saved_model": ["python.lite.TFLiteConverterBaseV2._load_saved_model", "<builtin>.set", "saved_model.save_options.SaveOptions", "<builtin>.len", "python.lite.TFLiteConverterBase._parse_saved_model_args", "saved_model.load.load", "python.saved_model.save", "<builtin>.ValueError"], "python.lite.TFLiteFrozenGraphConverterV2._convert_as_saved_model": ["shutil.rmtree", "<builtin>.super", "python.lite.TFLiteFrozenGraphConverterV2._convert_concrete_functions_to_saved_model", "tempfile.mkdtemp"], "python.lite.TFLiteFrozenGraphConverterV2.convert": ["python.lite.TFLiteConverterBaseV2._optimize_tf_model", "python.lite.TFLiteFrozenGraphConverterV2._freeze_concrete_function", "<builtin>.super", "python.lite.TFLiteFrozenGraphConverterV2._convert_as_saved_model"], "python.lite.TFLiteConverterV2.__init__": ["<builtin>.super"], "python.lite.TFLiteConverterV2.from_concrete_functions": ["python.lite.TFLiteConverterV2.__init__", "absl.logging.warning", "<builtin>.isinstance", "<builtin>.ValueError"], "python.lite.TFLiteConverterV2.from_saved_model": ["python.lite.TFLiteSavedModelConverterV2.__init__", "absl.logging.warning", "<builtin>.ValueError", "<builtin>.set", "<builtin>.len", "eager.context.eager_mode", "eager.context.executing_eagerly", "saved_model.load.load", "python.lite.TFLiteConverterV2.__init__", "python.lite.TFLiteConverter.from_saved_model"], "eager.context.executing_eagerly": [], "python.lite.TFLiteConverter.from_saved_model": ["python.convert_saved_model.freeze_saved_model", "python.lite.TFLiteSavedModelConverter.__init__", "python.util.build_debug_info_func", "<builtin>.set", "python.lite.TFLiteConverter.__init__"], "eager.context.eager_mode": [], "python.lite.TFLiteConverterV2.from_keras_model": ["python.lite.TFLiteKerasModelConverterV2.__init__"], "python.lite.TFLiteConverterV2.convert": ["<builtin>.super"], "python.lite.TFLiteConverterBaseV1.__init__": ["<builtin>.super"], "python.lite.TFLiteConverterBaseV1.__setattr__": ["warnings.warn"], "warnings.warn": [], "python.lite.TFLiteConverterBaseV1.__getattribute__": ["warnings.warn", "<builtin>.set"], "python.lite.TFLiteConverterBaseV1._validate_quantized_input_stats": ["<builtin>.frozenset", "python.util.get_tf_type_name", "<builtin>.ValueError", "python.lite.QuantizationMode.is_post_training_integer_quantize"], "python.util.get_tf_type_name": [], "python.lite.TFLiteConverterBaseV1": ["python.convert_phase.convert_phase"], "python.lite.TFLiteConverterBaseV1._validate_inputs": ["python.lite.TFLiteConverterBaseV1._set_batch_size", "python.lite.TFLiteConverterBaseV1.get_input_arrays", "python.lite.TFLiteConverterBaseV1._has_valid_tensors", "python.lite.TFLiteConverterBaseV1._is_unknown_shapes_allowed", "python.util.get_tensor_name", "<builtin>.ValueError"], "python.lite.TFLiteConverterBaseV1._is_unknown_shapes_allowed": ["<builtin>.super", "python.op_hint.is_ophint_converted", "absl.logging.warning"], "python.lite.TFLiteConverterBaseV1._has_valid_tensors": [], "python.lite.TFLiteConverterBaseV1._set_batch_size": ["python.lite.TFLiteConverterBaseV1._has_valid_tensors", "<builtin>.ValueError"], "python.lite.TFLiteConverterBaseV1.get_input_arrays": ["python.lite.TFLiteConverterBaseV1._has_valid_tensors", "python.util.get_tensor_name"], "python.lite.TFLiteConverterBaseV1._optimize_tf_model": ["python.lite.TFLiteConverterBase._grappler_config", "python.lite.QuantizationMode.contains_training_quant_op", "python.util.run_graph_optimizations", "framework.convert_to_constants.disable_lower_using_switch_merge"], "framework.convert_to_constants.disable_lower_using_switch_merge": [], "python.lite.TFLiteConverterBaseV1.convert": ["python.lite.QuantizationMode.__init__", "python.convert.toco_convert_impl", "python.lite.TFLiteConverterBaseV1._optimize_tf_model", "python.lite.TFLiteConverterBaseV1._has_valid_tensors", "absl.logging.warning", "python.lite.TFLiteConverterBaseV1._validate_inputs", "absl.logging.info", "python.convert.toco_convert_graph_def", "python.lite.QuantizationMode.converter_flags", "python.lite.TFLiteConverterBase._get_base_converter_args", "python.lite.TFLiteConverterBaseV1._validate_quantized_input_stats", "python.util.get_debug_info", "python.lite.TFLiteConverterBase._optimize_tflite_model", "python.lite.TFLiteConverterBase._validate_experimental_new_quantizer_flag"], "python.convert.toco_convert_graph_def": [], "python.op_hint.is_ophint_converted": [], "python.lite.TFLiteConverterBaseV1._save_conversion_params_metric": ["<builtin>.super"], "python.lite.TFLiteSavedModelConverter.__init__": ["python.convert_saved_model.freeze_saved_model", "<builtin>.super", "<builtin>.len", "python.lite.TFLiteConverterBase._parse_saved_model_args", "<builtin>.ValueError"], "python.lite.TFLiteSavedModelConverter": ["python.lite._export_metrics"], "python.lite.TFLiteSavedModelConverter.convert": ["<builtin>.super"], "python.lite.TFLiteKerasModelConverter.__init__": ["python.util.freeze_graph", "util.keras_deps.get_clear_session_function", "util.keras_deps.get_get_session_function", "python.util.build_debug_info_func", "<builtin>.ValueError", "python.util.get_tensors_from_tensor_names", "python.util.set_tensor_shapes", "<builtin>.super", "framework.convert_to_constants.convert_variables_to_constants_v2", "eager.context.executing_eagerly", "python.util.trace_model_call", "util.keras_deps.get_load_model_function"], "util.keras_deps.get_load_model_function": [], "framework.convert_to_constants.convert_variables_to_constants_v2": [], "python.util.set_tensor_shapes": [], "util.keras_deps.get_clear_session_function": [], "util.keras_deps.get_get_session_function": [], "python.util.get_tensors_from_tensor_names": [], "python.util.freeze_graph": [], "python.lite.TFLiteKerasModelConverter": ["python.convert_phase.convert_phase", "python.lite._export_metrics"], "python.lite.TFLiteKerasModelConverter._freeze_keras_model": ["python.convert_saved_model.freeze_saved_model", "python.util.build_debug_info_func", "python.lite.TFLiteConverterBase._parse_saved_model_args", "<builtin>.set"], "python.lite.TFLiteKerasModelConverter._convert_as_saved_model": ["<builtin>.super", "shutil.rmtree", "python.lite.TFLiteKerasModelConverter._freeze_keras_model", "tempfile.mkdtemp"], "python.lite.TFLiteKerasModelConverter.convert": ["python.lite.TFLiteKerasModelConverter._convert_as_saved_model", "<builtin>.super"], "python.lite.TFLiteFrozenGraphConverter.__init__": ["python.lite.TFLiteConverterBaseV1._has_valid_tensors", "<builtin>.super", "absl.logging.warning"], "python.lite.TFLiteFrozenGraphConverter": ["python.lite._export_metrics"], "python.lite.TFLiteFrozenGraphConverter.convert": ["python.lite.TFLiteConverterBaseV1._has_valid_tensors", "<builtin>.super", "<builtin>.ValueError"], "python.lite.TFLiteConverter.__init__": ["<builtin>.super"], "python.lite.TFLiteConverter.from_session": ["python.util.freeze_graph", "python.util.build_debug_info_func", "python.lite.TFLiteConverter.__init__"], "python.lite.TFLiteConverter.from_frozen_graph": ["framework.graph_pb2.GraphDef", "platform.gfile.Exists", "client.session.Session", "protobuf.text_format.Merge", "framework.importer.import_graph_def", "python.util.is_frozen_graph", "<builtin>.IOError", "six.ensure_binary", "<builtin>.ValueError", "python.util.get_tensors_from_tensor_names", "python.util.set_tensor_shapes", "<builtin>.set", "framework.ops.Graph", "six.ensure_text", "platform.gfile.GFile", "python.lite.TFLiteConverter.__init__", "<builtin>.isinstance", "<builtin>.print"], "client.session.Session": [], "platform.gfile.Exists": [], "<builtin>.IOError": [], "platform.gfile.GFile": [], "framework.graph_pb2.GraphDef": [], "<builtin>.print": [], "six.ensure_binary": [], "six.ensure_text": [], "protobuf.text_format.Merge": [], "framework.importer.import_graph_def": [], "python.util.is_frozen_graph": [], "python.lite.TFLiteConverter.from_keras_model_file": ["python.lite.TFLiteKerasModelConverter.__init__"], "python.lite.TFLiteConverter.convert": ["<builtin>.super"], "util.deprecation.deprecated": [], "python.lite.TocoConverter": ["util.deprecation.deprecated"], "python.lite.TocoConverter.from_session": ["python.lite.TFLiteConverter.from_session"], "python.lite.TocoConverter.from_frozen_graph": ["python.lite.TFLiteConverter.from_frozen_graph"], "python.lite.TocoConverter.from_saved_model": ["python.lite.TFLiteConverter.from_saved_model"], "python.lite.TocoConverter.from_keras_model_file": ["python.lite.TFLiteConverter.from_keras_model_file"]}