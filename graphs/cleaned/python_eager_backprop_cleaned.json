{"eager.backprop": ["python.pywrap_tfe.TFE_Py_RegisterVSpace", "python.pywrap_tfe.TFE_Py_RegisterGradientFunction", "<builtin>.globals", "util.tf_export.tf_export", "util.lazy_loader.LazyLoader", "eager.imperative_grad.VSpace"], "<builtin>.globals": [], "util.lazy_loader.LazyLoader": [], "eager.backprop.op_attr_type": ["eager.context.context", "python.pywrap_tfe.TFE_OpNameGetAttrType", "eager.context.ensure_initialized"], "eager.context.ensure_initialized": [], "eager.context.context": [], "python.pywrap_tfe.TFE_OpNameGetAttrType": [], "eager.backprop.make_attr": ["framework.tensor_shape.as_shape", "framework.dtypes.as_dtype", "<builtin>.isinstance", "<builtin>.int"], "<builtin>.int": [], "framework.dtypes.as_dtype": [], "framework.tensor_shape.as_shape": [], "<builtin>.isinstance": [], "eager.backprop._MockOp.__init__": [], "eager.backprop._MockOp.get_attr": ["<builtin>.range", "eager.backprop.op_attr_type", "<builtin>.len", "eager.backprop.make_attr", "<builtin>.KeyError"], "<builtin>.len": [], "<builtin>.range": [], "<builtin>.KeyError": [], "eager.backprop._MockOp._get_control_flow_context": ["<builtin>.NotImplementedError"], "<builtin>.NotImplementedError": [], "eager.backprop._gradient_function": ["framework.ops.executing_eagerly_outside_functions", "ops.control_flow_util.EnableControlFlowV2", "framework.ops.get_default_graph", "framework.ops.name_scope", "ops._gradient_registry.lookup", "eager.backprop._MockOp.__init__"], "ops._gradient_registry.lookup": [], "framework.ops.executing_eagerly_outside_functions": [], "framework.ops.get_default_graph": [], "ops.control_flow_util.EnableControlFlowV2": [], "framework.ops.name_scope": [], "python.pywrap_tfe.TFE_Py_RegisterGradientFunction": [], "eager.backprop._must_record_gradient": ["python.pywrap_tfe.TFE_Py_TapeSetIsEmpty"], "python.pywrap_tfe.TFE_Py_TapeSetIsEmpty": [], "util.tf_export.tf_export": [], "eager.backprop.record_gradient": ["framework.ops.get_name_scope", "python.pywrap_tfe.TFE_Py_RecordGradient"], "framework.ops.get_name_scope": [], "python.pywrap_tfe.TFE_Py_RecordGradient": [], "eager.backprop.implicit_val_and_grad": [], "eager.backprop.implicit_val_and_grad.grad_fn": ["eager.tape.push_new_tape", "eager.imperative_grad.imperative_grad", "<builtin>.ValueError", "<builtin>.getattr", "eager.tape.pop_tape", "util.nest.flatten", "<builtin>.list", "<builtin>.zip"], "eager.tape.push_new_tape": [], "<builtin>.ValueError": [], "eager.tape.pop_tape": [], "<builtin>.getattr": [], "util.nest.flatten": [], "eager.imperative_grad.imperative_grad": [], "<builtin>.zip": [], "<builtin>.list": [], "eager.backprop.implicit_grad": [], "eager.backprop.implicit_grad.grad_fn": ["eager.backprop.implicit_val_and_grad", "eager.backprop.implicit_val_and_grad.grad_fn"], "eager.backprop._get_arg_spec": ["<builtin>.isinstance", "<builtin>.range", "<builtin>.ValueError", "util.tf_inspect.getfullargspec", "<builtin>.all", "<builtin>.len"], "util.tf_inspect.getfullargspec": [], "<builtin>.all": [], "eager.backprop.gradients_function": [], "eager.backprop.gradients_function.decorated": ["eager.backprop.val_and_grad_function", "eager.backprop.val_and_grad_function.decorated"], "eager.backprop.val_and_grad_function": [], "eager.backprop.val_and_grad_function.decorated": ["<builtin>.ValueError", "eager.backprop.make_vjp", "eager.backprop.make_vjp.decorated"], "eager.backprop._ensure_unique_tensor_objects": ["<builtin>.set", "ops.gen_array_ops.identity", "framework.ops.tensor_id", "<builtin>.enumerate"], "<builtin>.set": [], "<builtin>.enumerate": [], "framework.ops.tensor_id": [], "ops.gen_array_ops.identity": [], "eager.backprop.make_vjp": [], "eager.backprop.make_vjp.decorated": ["eager.tape.push_new_tape", "eager.backprop._get_arg_spec", "<builtin>.ValueError", "<builtin>.getattr", "framework.ops.convert_to_tensor", "util.nest.flatten", "eager.tape.watch", "eager.tape.pop_tape", "util.nest.pack_sequence_as", "ops.gen_array_ops.identity", "eager.backprop._ensure_unique_tensor_objects", "<builtin>.enumerate"], "framework.ops.convert_to_tensor": [], "eager.tape.watch": [], "util.nest.pack_sequence_as": [], "eager.backprop.make_vjp.decorated.vjp": ["util.nest.flatten", "eager.imperative_grad.imperative_grad", "framework.ops.convert_to_tensor"], "eager.backprop.flatten_nested_indexed_slices": ["framework.ops.IndexedSlices", "ops.array_ops.gather", "eager.backprop.flatten_nested_indexed_slices", "<builtin>.isinstance"], "ops.array_ops.gather": [], "framework.ops.IndexedSlices": [], "eager.backprop.aggregate_indexed_slices_gradients": ["<builtin>.isinstance", "ops.array_ops.concat", "framework.ops.IndexedSlices", "<builtin>.len", "ops.math_ops.add_n", "eager.backprop.flatten_nested_indexed_slices", "<builtin>.any", "ops.math_ops._as_indexed_slices_list"], "<builtin>.any": [], "ops.math_ops.add_n": [], "ops.math_ops._as_indexed_slices_list": [], "ops.array_ops.concat": [], "eager.backprop._aggregate_grads": ["<builtin>.isinstance", "<builtin>.all", "<builtin>.len", "eager.backprop.aggregate_indexed_slices_gradients", "ops.gen_math_ops.add_n"], "ops.gen_math_ops.add_n": [], "eager.backprop._num_elements": ["<builtin>.ValueError", "<builtin>.isinstance", "functools.reduce"], "functools.reduce": [], "eager.backprop._fast_fill": ["ops.array_ops.fill", "framework.constant_op.constant"], "framework.constant_op.constant": [], "ops.array_ops.fill": [], "eager.backprop._zeros": ["eager.backprop._fast_fill", "eager.context.context", "framework.dtypes.as_dtype", "framework.tensor_util.is_tf_type", "ops.array_ops.zeros"], "ops.array_ops.zeros": [], "framework.tensor_util.is_tf_type": [], "eager.backprop._ones": ["framework.constant_op.constant", "eager.backprop._fast_fill", "framework.dtypes.as_dtype", "eager.context.executing_eagerly", "ops.array_ops.ones"], "eager.context.executing_eagerly": [], "ops.array_ops.ones": [], "eager.imperative_grad.VSpace": [], "python.pywrap_tfe.TFE_Py_RegisterVSpace": [], "eager.backprop._handle_or_self": ["ops.resource_variable_ops.is_resource_variable"], "ops.resource_variable_ops.is_resource_variable": [], "eager.backprop.GradientTape.__init__": [], "eager.backprop.GradientTape.__enter__": ["eager.backprop.GradientTape._push_tape"], "eager.backprop.GradientTape._push_tape": ["<builtin>.ValueError", "eager.tape.push_new_tape", "eager.tape.push_tape"], "eager.backprop.GradientTape.__exit__": ["eager.backprop.GradientTape._pop_tape"], "eager.backprop.GradientTape._pop_tape": ["<builtin>.ValueError", "eager.tape.pop_tape"], "eager.tape.push_tape": [], "eager.backprop.GradientTape": ["util.tf_contextlib.contextmanager"], "util.tf_contextlib.contextmanager": [], "eager.backprop.GradientTape._ensure_recording": ["eager.backprop.GradientTape._pop_tape", "eager.backprop.GradientTape._push_tape"], "eager.backprop.GradientTape.watch": ["eager.backprop_util.IsTrainable", "<builtin>.ValueError", "util._pywrap_utils.IsTensor", "util.nest.flatten", "eager.tape.watch", "eager.tape.watch_variable", "platform.tf_logging.log_first_n", "util._pywrap_utils.IsVariable", "<builtin>.hasattr", "<builtin>.type"], "util._pywrap_utils.IsTensor": [], "util._pywrap_utils.IsVariable": [], "<builtin>.type": [], "eager.backprop_util.IsTrainable": [], "platform.tf_logging.log_first_n": [], "<builtin>.hasattr": [], "eager.tape.watch_variable": [], "eager.backprop.GradientTape.stop_recording": ["eager.backprop.GradientTape._pop_tape", "eager.backprop.GradientTape._push_tape", "<builtin>.RuntimeError"], "<builtin>.RuntimeError": [], "eager.backprop.GradientTape.reset": ["eager.backprop.GradientTape._pop_tape", "eager.backprop.GradientTape._push_tape"], "eager.backprop.GradientTape.watched_variables": [], "eager.backprop.GradientTape.gradient": ["platform.tf_logging.vlog", "eager.backprop._handle_or_self", "eager.backprop.GradientTape._pop_tape", "eager.backprop_util.IsTrainable", "ops.resource_variable_ops.is_resource_variable", "<builtin>.RuntimeError", "<builtin>.ValueError", "eager.imperative_grad.imperative_grad", "<builtin>.getattr", "<builtin>.TypeError", "framework.ops.convert_to_tensor", "util.nest.flatten", "platform.tf_logging.log_first_n", "util.nest.pack_sequence_as"], "<builtin>.TypeError": [], "platform.tf_logging.vlog": [], "eager.backprop.GradientTape.jacobian": ["sys.exc_info", "eager.backprop.GradientTape._ensure_recording", "six.reraise", "ops.array_ops.concat", "<builtin>.ValueError", "eager.context.executing_eagerly", "<builtin>.len", "util.nest.flatten", "<builtin>.str", "ops.array_ops.reshape", "ops.array_ops.shape", "<builtin>.RuntimeError", "util.nest.pack_sequence_as", "<builtin>.enumerate", "<builtin>.int"], "ops.array_ops.shape": [], "ops.array_ops.reshape": [], "eager.backprop.GradientTape.jacobian.loop_fn": ["eager.backprop.GradientTape._ensure_recording", "ops.array_ops.gather", "eager.backprop.GradientTape.gradient"], "<builtin>.str": [], "sys.exc_info": [], "six.reraise": [], "eager.backprop.GradientTape.batch_jacobian": ["sys.exc_info", "eager.backprop.GradientTape._ensure_recording", "six.reraise", "ops.array_ops.transpose", "ops.array_ops.concat", "<builtin>.ValueError", "ops.array_ops.zeros", "eager.context.executing_eagerly", "framework.tensor_shape.Dimension", "framework.ops.control_dependencies", "<builtin>.str", "ops.array_ops.reshape", "ops.array_ops.shape", "ops.check_ops.assert_equal", "<builtin>.RuntimeError", "ops.array_ops.size", "<builtin>.int"], "framework.tensor_shape.Dimension": [], "ops.array_ops.size": [], "ops.check_ops.assert_equal": [], "framework.ops.control_dependencies": [], "eager.backprop.GradientTape.batch_jacobian.loop_fn": ["eager.backprop.GradientTape._ensure_recording", "ops.array_ops.gather", "eager.backprop.GradientTape.gradient", "<builtin>.RuntimeError"], "ops.array_ops.transpose": []}