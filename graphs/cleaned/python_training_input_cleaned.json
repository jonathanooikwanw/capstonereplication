{"training.input": ["util.deprecation.deprecated_endpoints", "util.tf_export.tf_export", "util.deprecation.deprecated"], "util.tf_export.tf_export": [], "util.deprecation.deprecated_endpoints": [], "training.input.match_filenames_once": ["framework.ops.name_scope", "ops.io_ops.matching_files", "ops.variable_scope.variable"], "framework.ops.name_scope": [], "ops.io_ops.matching_files": [], "ops.variable_scope.variable": [], "util.deprecation.deprecated": [], "training.input.limit_epochs": ["ops.array_ops.identity", "framework.ops.control_dependencies", "<builtin>.ValueError", "framework.ops.name_scope", "framework.constant_op.constant", "ops.variable_scope.variable"], "<builtin>.ValueError": [], "framework.constant_op.constant": [], "framework.ops.control_dependencies": [], "ops.array_ops.identity": [], "training.input.input_producer": ["summary.summary.scalar", "training.queue_runner.add_queue_runner", "ops.data_flow_ops.FIFOQueue", "training.queue_runner.QueueRunner", "framework.ops.convert_to_tensor", "<builtin>.ValueError", "training.input.limit_epochs", "ops.math_ops.cast", "ops.random_ops.random_shuffle", "framework.ops.name_scope", "eager.context.executing_eagerly", "<builtin>.RuntimeError"], "eager.context.executing_eagerly": [], "<builtin>.RuntimeError": [], "framework.ops.convert_to_tensor": [], "ops.random_ops.random_shuffle": [], "ops.data_flow_ops.FIFOQueue": [], "training.queue_runner.QueueRunner": [], "training.queue_runner.add_queue_runner": [], "ops.math_ops.cast": [], "summary.summary.scalar": [], "training.input.string_input_producer": ["ops.array_ops.identity", "ops.control_flow_ops.Assert", "framework.ops.control_dependencies", "<builtin>.isinstance", "framework.ops.convert_to_tensor", "<builtin>.ValueError", "ops.array_ops.size", "framework.ops.name_scope", "training.input.input_producer", "ops.math_ops.greater"], "<builtin>.isinstance": [], "ops.array_ops.size": [], "ops.math_ops.greater": [], "ops.control_flow_ops.Assert": [], "training.input.range_input_producer": ["ops.math_ops.range", "framework.ops.name_scope", "training.input.input_producer"], "ops.math_ops.range": [], "training.input.slice_input_producer": ["training.input.range_input_producer", "framework.ops.convert_n_to_tensor_or_indexed_slices", "<builtin>.ValueError", "ops.array_ops.gather", "framework.ops.name_scope", "ops.array_ops.shape"], "framework.ops.convert_n_to_tensor_or_indexed_slices": [], "ops.array_ops.shape": [], "ops.array_ops.gather": [], "training.input._flatten": [], "training.input._SparseMetaData.__init__": ["framework.tensor_shape.as_dimension"], "framework.tensor_shape.as_dimension": [], "training.input._SparseMetaData.__eq__": [], "training.input._SparseMetaData.__ne__": ["training.input._SparseMetaData.__eq__"], "training.input._SparseMetaData.__str__": [], "training.input._SparseMetaData.merge_with": ["<builtin>.ValueError"], "training.input._SparseMetaData.map_op": [], "training.input._SparseMetaData.sparse": [], "training.input._SparseMetaData.rank": [], "training.input._as_tensor_list": ["<builtin>.isinstance", "<builtin>.sorted"], "<builtin>.sorted": [], "training.input._as_tensor_list_list": ["<builtin>.isinstance", "<builtin>.set", "training.input._as_tensor_list", "<builtin>.ValueError"], "<builtin>.set": [], "training.input._as_original_type": ["<builtin>.isinstance", "<builtin>.len", "<builtin>.enumerate", "<builtin>.sorted"], "<builtin>.len": [], "<builtin>.enumerate": [], "training.input._store_sparse_tensors": ["ops.array_ops.expand_dims", "<builtin>.zip", "training.input._store_sparse_tensors._maybe_store", "training.input._store_sparse_tensors._sparse_op", "<builtin>.len", "training.input._store_sparse_tensors._sparse_meta_data"], "training.input._store_sparse_tensors._sparse_meta_data": ["<builtin>.isinstance", "training.input._SparseMetaData.__init__"], "training.input._store_sparse_tensors._maybe_store": ["training.input._store_sparse_tensors._maybe_store._sparse_values_to_keep", "training.input._store_sparse_tensors._maybe_store._maybe_store_many_sparse", "<builtin>.isinstance", "ops.sparse_ops.sparse_retain", "training.input._store_sparse_tensors._maybe_store.<lambda1>", "training.input._store_sparse_tensors._maybe_store._maybe_store_sparse"], "training.input._store_sparse_tensors._maybe_store._maybe_store_sparse": ["layers.utils.smart_cond"], "training.input._store_sparse_tensors._maybe_store._maybe_store_sparse.<lambda1>": ["ops.sparse_ops._add_sparse_to_tensors_map"], "ops.sparse_ops._add_sparse_to_tensors_map": [], "training.input._store_sparse_tensors._maybe_store._maybe_store_sparse.<lambda2>": ["framework.constant_op.constant"], "layers.utils.smart_cond": [], "training.input._store_sparse_tensors._maybe_store._maybe_store_many_sparse": ["layers.utils.smart_cond"], "training.input._store_sparse_tensors._maybe_store._maybe_store_many_sparse.<lambda1>": ["ops.sparse_ops._add_many_sparse_to_tensors_map"], "ops.sparse_ops._add_many_sparse_to_tensors_map": [], "training.input._store_sparse_tensors._maybe_store._maybe_store_many_sparse.<lambda2>": ["ops.array_ops.ones", "ops.array_ops.shape"], "ops.array_ops.ones": [], "training.input._store_sparse_tensors._maybe_store._sparse_values_to_keep": ["ops.array_ops.gather"], "ops.sparse_ops.sparse_retain": [], "training.input._store_sparse_tensors._maybe_store.<lambda1>": ["ops.sparse_ops._add_many_sparse_to_tensors_map"], "<builtin>.zip": [], "training.input._store_sparse_tensors._sparse_op": [], "ops.array_ops.expand_dims": [], "training.input._store_sparse_tensors_join": ["training.input._store_sparse_tensors", "<builtin>.ValueError", "<builtin>.zip"], "training.input._restore_sparse_tensors": ["<builtin>.zip", "<builtin>.any", "framework.sparse_tensor.SparseTensor", "<builtin>.isinstance", "ops.sparse_ops._take_many_sparse_from_tensors_map", "training.input._restore_sparse_tensors.<lambda1>", "framework.tensor_shape.dimension_value", "ops.array_ops.squeeze"], "ops.array_ops.squeeze": [], "framework.tensor_shape.dimension_value": [], "ops.sparse_ops._take_many_sparse_from_tensors_map": [], "<builtin>.any": [], "training.input._restore_sparse_tensors.<lambda1>": ["ops.control_flow_ops.with_dependencies"], "ops.control_flow_ops.with_dependencies": [], "framework.sparse_tensor.SparseTensor": [], "training.input._validate": ["framework.ops.convert_n_to_tensor_or_indexed_slices", "<builtin>.ValueError"], "training.input._validate_join": ["framework.ops.convert_n_to_tensor_or_indexed_slices", "<builtin>.ValueError"], "training.input._validate_keep_input": ["framework.ops.convert_to_tensor", "<builtin>.ValueError"], "training.input._dtypes": ["<builtin>.TypeError"], "<builtin>.TypeError": [], "training.input._merge_shapes": ["framework.tensor_shape.as_shape"], "framework.tensor_shape.as_shape": [], "training.input._shapes": ["<builtin>.len", "<builtin>.ValueError", "training.input._merge_shapes", "six.moves.xrange"], "six.moves.xrange": [], "training.input._select_which_to_enqueue": ["ops.data_flow_ops.dynamic_partition", "ops.math_ops.cast"], "ops.data_flow_ops.dynamic_partition": [], "training.input._enqueue_join": ["training.input._select_which_to_enqueue", "layers.utils.smart_cond", "training.queue_runner.QueueRunner", "training.queue_runner.add_queue_runner"], "training.input._enqueue_join.<lambda1>": [], "training.input._enqueue": ["training.input._select_which_to_enqueue", "layers.utils.smart_cond", "training.queue_runner.QueueRunner", "training.queue_runner.add_queue_runner"], "training.input._enqueue.<list2>.<lambda1>": [], "training.input._which_queue": [], "training.input._batch": ["training.input._store_sparse_tensors", "training.input._shapes", "training.input._enqueue", "training.input._dtypes", "training.input._validate", "training.input._which_queue", "training.input._as_tensor_list", "training.input._as_original_type", "<builtin>.ValueError", "training.input._restore_sparse_tensors", "ops.math_ops.cast", "training.input._validate_keep_input", "<builtin>.list", "framework.ops.name_scope", "eager.context.executing_eagerly", "summary.summary.scalar"], "<builtin>.list": [], "training.input._batch_join": ["training.input._flatten", "training.input._shapes", "training.input._dtypes", "training.input._store_sparse_tensors_join", "training.input._as_tensor_list_list", "training.input._which_queue", "training.input._as_original_type", "<builtin>.ValueError", "training.input._restore_sparse_tensors", "training.input._validate_join", "ops.math_ops.cast", "training.input._enqueue_join", "training.input._validate_keep_input", "framework.ops.name_scope", "eager.context.executing_eagerly", "summary.summary.scalar"], "training.input._shuffle_batch": ["training.input._store_sparse_tensors", "training.input._shapes", "training.input._enqueue", "training.input._dtypes", "ops.data_flow_ops.RandomShuffleQueue", "ops.math_ops.maximum", "training.input._validate", "training.input._as_tensor_list", "training.input._as_original_type", "<builtin>.ValueError", "training.input._restore_sparse_tensors", "ops.math_ops.cast", "training.input._validate_keep_input", "<builtin>.list", "framework.ops.name_scope", "eager.context.executing_eagerly", "summary.summary.scalar"], "ops.data_flow_ops.RandomShuffleQueue": [], "ops.math_ops.maximum": [], "training.input._shuffle_batch_join": ["training.input._flatten", "training.input._shapes", "training.input._dtypes", "training.input._store_sparse_tensors_join", "ops.data_flow_ops.RandomShuffleQueue", "training.input._as_tensor_list_list", "ops.math_ops.maximum", "training.input._as_original_type", "<builtin>.ValueError", "training.input._restore_sparse_tensors", "training.input._validate_join", "ops.math_ops.cast", "training.input._enqueue_join", "training.input._validate_keep_input", "framework.ops.name_scope", "eager.context.executing_eagerly", "summary.summary.scalar"], "training.input.batch": ["training.input._batch"], "training.input.maybe_batch": ["training.input._batch"], "training.input.batch_join": ["training.input._batch_join"], "training.input.maybe_batch_join": ["training.input._batch_join"], "training.input.shuffle_batch": ["training.input._shuffle_batch"], "training.input.maybe_shuffle_batch": ["training.input._shuffle_batch"], "training.input.shuffle_batch_join": ["training.input._shuffle_batch_join"], "training.input.maybe_shuffle_batch_join": ["training.input._shuffle_batch_join"]}