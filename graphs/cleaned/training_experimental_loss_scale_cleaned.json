{"experimental.loss_scale": [], "experimental.loss_scale.LossScale.__init__": [], "experimental.loss_scale.LossScale": ["abc.abstractmethod"], "abc.abstractmethod": [], "experimental.loss_scale.LossScale.__call__": [], "experimental.loss_scale.LossScale.update": [], "experimental.loss_scale.LossScale._add_weight": ["eager.context.executing_eagerly", "base.Trackable._handle_deferred_dependencies", "framework.ops.get_default_graph", "<builtin>.RuntimeError", "ops.variable_scope.variable"], "ops.variable_scope.variable": [], "eager.context.executing_eagerly": [], "framework.ops.get_default_graph": [], "<builtin>.RuntimeError": [], "base.Trackable._handle_deferred_dependencies": [], "experimental.loss_scale.LossScale._checkpoint_dependencies": ["<builtin>.sorted", "eager.context.executing_eagerly", "tracking.base.TrackableReference", "framework.ops.get_default_graph", "<builtin>.super"], "experimental.loss_scale.LossScale._checkpoint_dependencies.<lambda1>": [], "<builtin>.sorted": [], "tracking.base.TrackableReference": [], "<builtin>.super": [], "experimental.loss_scale.LossScale._lookup_dependency": ["eager.context.executing_eagerly", "<builtin>.super", "framework.ops.get_default_graph"], "experimental.loss_scale.LossScale.get_config": [], "experimental.loss_scale.LossScale.from_config": ["experimental.loss_scale.LossScale.__init__"], "util.deprecation.deprecated": [], "experimental.loss_scale.FixedLossScale": ["util.deprecation.deprecated"], "experimental.loss_scale.FixedLossScale.__init__": ["<builtin>.isinstance", "<builtin>.super", "<builtin>.float", "<builtin>.ValueError"], "<builtin>.isinstance": [], "<builtin>.ValueError": [], "<builtin>.float": [], "experimental.loss_scale.FixedLossScale.__call__": ["framework.ops.convert_to_tensor"], "framework.ops.convert_to_tensor": [], "experimental.loss_scale.FixedLossScale.update": ["ops.control_flow_ops.no_op"], "ops.control_flow_ops.no_op": [], "experimental.loss_scale.FixedLossScale.__repr__": [], "experimental.loss_scale.FixedLossScale.get_config": [], "experimental.loss_scale._is_all_finite": ["ops.math_ops.is_finite", "ops.math_ops.reduce_all"], "ops.math_ops.is_finite": [], "ops.math_ops.reduce_all": [], "experimental.loss_scale._op_in_graph_mode": ["eager.context.executing_eagerly"], "experimental.loss_scale._assign_if_finite": ["ops.control_flow_ops.cond", "ops.math_ops.is_finite"], "experimental.loss_scale._assign_if_finite.<lambda1>": ["experimental.loss_scale._op_in_graph_mode"], "ops.control_flow_ops.cond": [], "experimental.loss_scale.DynamicLossScale": ["util.deprecation.deprecated"], "experimental.loss_scale.DynamicLossScale.__init__": ["<builtin>.super", "<builtin>.int", "<builtin>.float", "experimental.loss_scale.LossScale._add_weight"], "<builtin>.int": [], "experimental.loss_scale.DynamicLossScale.initial_loss_scale": [], "experimental.loss_scale.DynamicLossScale.increment_period": [], "experimental.loss_scale.DynamicLossScale.multiplier": [], "experimental.loss_scale.DynamicLossScale.__call__": ["framework.ops.convert_to_tensor"], "experimental.loss_scale.DynamicLossScale.update": ["experimental.loss_scale._is_all_finite", "ops.math_ops.equal", "distribute.distribution_strategy_context.get_cross_replica_context", "util.nest.flatten", "distribute.distribution_strategy_context.has_strategy", "ops.control_flow_ops.cond"], "util.nest.flatten": [], "distribute.distribution_strategy_context.has_strategy": [], "distribute.distribution_strategy_context.get_cross_replica_context": [], "experimental.loss_scale.DynamicLossScale.update.get_is_finite": ["experimental.loss_scale._is_all_finite", "ops.math_ops.cast"], "ops.math_ops.cast": [], "ops.math_ops.equal": [], "experimental.loss_scale.DynamicLossScale.update.update_if_finite_grads": ["ops.control_flow_ops.cond"], "experimental.loss_scale.DynamicLossScale.update.update_if_finite_grads.incr_loss_scale": ["experimental.loss_scale._assign_if_finite", "ops.control_flow_ops.group"], "ops.control_flow_ops.group": [], "experimental.loss_scale.DynamicLossScale.update.update_if_finite_grads.<lambda1>": ["experimental.loss_scale._op_in_graph_mode"], "experimental.loss_scale.DynamicLossScale.update.update_if_not_finite_grads": ["ops.math_ops.maximum", "ops.control_flow_ops.group"], "ops.math_ops.maximum": [], "experimental.loss_scale.DynamicLossScale.__repr__": ["eager.context.executing_eagerly"], "experimental.loss_scale.DynamicLossScale.get_config": [], "experimental.loss_scale.get": ["<builtin>.isinstance", "experimental.loss_scale.DynamicLossScale.__init__", "experimental.loss_scale.FixedLossScale.__init__", "<builtin>.ValueError"]}