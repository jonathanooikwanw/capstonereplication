{"ops.custom_gradient": ["util.tf_export.tf_export"], "util.tf_export.tf_export": [], "ops.custom_gradient.custom_gradient": ["ops.custom_gradient.custom_gradient.decorated", "util.tf_decorator.make_decorator", "ops.custom_gradient.Bind.decorator"], "ops.custom_gradient.custom_gradient.<lambda1>": ["ops.custom_gradient.custom_gradient"], "ops.custom_gradient.Bind.decorator": [], "ops.custom_gradient.custom_gradient.decorated": ["ops.custom_gradient._eager_mode_decorator", "ops.custom_gradient._graph_mode_decorator", "eager.context.executing_eagerly"], "eager.context.executing_eagerly": [], "ops.custom_gradient._eager_mode_decorator": ["framework.ops.convert_to_tensor", "<builtin>.all", "util.tf_inspect.getfullargspec", "ops.custom_gradient.recompute_grad.inner", "<builtin>.TypeError", "ops.custom_gradient.recompute_grad.inner.grad_wrapper.inner_recompute_grad", "util.nest.pack_sequence_as", "ops.custom_gradient.grad_pass_through._grad_pass_through_op", "util.nest.flatten", "eager.tape.VariableWatcher", "ops.gen_array_ops.identity", "<builtin>.len", "<builtin>.set", "<builtin>.list", "eager.tape.record_operation"], "ops.custom_gradient._graph_mode_decorator": ["<builtin>.getattr", "util.nest.pack_sequence_as", "util.nest.flatten", "framework.ops.RegisterGradient", "eager.tape.VariableWatcher", "ops.custom_gradient._get_dependent_variables", "framework.ops.convert_to_tensor", "<builtin>.enumerate", "ops.variable_scope.get_variable_scope", "ops.custom_gradient.recompute_grad.inner", "util.tf_inspect.getfullargspec", "ops.array_ops.identity_n", "<builtin>.ValueError", "ops.custom_gradient.generate_name", "<builtin>.zip", "ops.resource_variable_ops.is_resource_variable", "platform.tf_logging.warn", "framework.ops.get_default_graph", "util.nest.map_structure", "<builtin>.len", "<builtin>.set", "eager.tape.record_operation", "<builtin>.TypeError", "<builtin>.frozenset", "ops.custom_gradient.recompute_grad.inner.grad_wrapper.inner_recompute_grad", "ops.custom_gradient.grad_pass_through._grad_pass_through_op", "<builtin>.hasattr", "<builtin>.sorted", "ops.handle_data_util.copy_handle_data"], "util.tf_decorator.make_decorator": [], "ops.custom_gradient.Bind.decorator.<lambda1>": ["ops.custom_gradient.Bind.__init__"], "ops.custom_gradient.Bind.__init__": [], "ops.custom_gradient.Bind.__get__": ["util.tf_decorator.make_decorator", "ops.custom_gradient.Bind.__init__"], "ops.custom_gradient.Bind.__call__": [], "ops.custom_gradient.get_variable_by_name": ["<builtin>.ValueError", "<builtin>.filter", "framework.ops.get_collection", "<builtin>.len", "<builtin>.list"], "framework.ops.get_collection": [], "ops.custom_gradient.get_variable_by_name._filter_fn": [], "<builtin>.filter": [], "<builtin>.list": [], "<builtin>.len": [], "<builtin>.ValueError": [], "ops.custom_gradient._get_dependent_variables": ["util.nest.map_structure", "ops.op_selector.get_backward_walk_ops", "ops.custom_gradient.get_variable_by_name"], "util.nest.map_structure": [], "ops.op_selector.get_backward_walk_ops": [], "ops.custom_gradient.generate_name": ["framework.ops.uid"], "framework.ops.uid": [], "ops.variable_scope.get_variable_scope": [], "<builtin>.set": [], "eager.tape.VariableWatcher": [], "ops.custom_gradient.recompute_grad.inner": ["eager.tape.stop_recording", "ops.variable_scope.get_variable_scope"], "ops.custom_gradient.recompute_grad.inner.grad_wrapper.inner_recompute_grad": ["<builtin>.float", "ops.math_ops.cast", "ops.math_ops.reduce_max", "util.nest.map_structure", "ops.variable_scope.variable_scope", "<builtin>.len", "eager.backprop.GradientTape", "eager.context.executing_eagerly", "<builtin>.list", "ops.array_ops.reshape", "ops.array_ops.where_v2"], "ops.custom_gradient.grad_pass_through._grad_pass_through_op": [], "util.nest.flatten": [], "ops.resource_variable_ops.is_resource_variable": [], "<builtin>.TypeError": [], "<builtin>.frozenset": [], "<builtin>.getattr": [], "ops.custom_gradient._graph_mode_decorator.<lambda1>": [], "<builtin>.sorted": [], "util.tf_inspect.getfullargspec": [], "platform.tf_logging.warn": [], "ops.custom_gradient._graph_mode_decorator.tape_grad_fn": ["<builtin>.ValueError", "<builtin>.len", "util.nest.flatten"], "framework.ops.RegisterGradient": [], "ops.custom_gradient._graph_mode_decorator.internal_grad_fn": ["ops.custom_gradient._graph_mode_decorator.tape_grad_fn"], "framework.ops.get_default_graph": [], "ops.array_ops.identity_n": [], "framework.ops.convert_to_tensor": [], "<builtin>.enumerate": [], "<builtin>.hasattr": [], "eager.tape.record_operation": [], "<builtin>.zip": [], "ops.handle_data_util.copy_handle_data": [], "util.nest.pack_sequence_as": [], "<builtin>.all": [], "ops.gen_array_ops.identity": [], "ops.custom_gradient._eager_mode_decorator.actual_grad_fn": ["<builtin>.ValueError", "<builtin>.len", "util.nest.flatten"], "ops.custom_gradient.recompute_grad": ["ops.custom_gradient.custom_gradient"], "eager.tape.stop_recording": [], "ops.custom_gradient.recompute_grad.inner.grad_wrapper": ["ops.custom_gradient.recompute_grad.inner.grad_wrapper.inner_recompute_grad", "ops.custom_gradient.custom_gradient"], "eager.backprop.GradientTape": [], "ops.array_ops.reshape": [], "ops.math_ops.reduce_max": [], "ops.math_ops.cast": [], "<builtin>.float": [], "ops.array_ops.where_v2": [], "ops.custom_gradient.recompute_grad.inner.grad_wrapper.inner_recompute_grad.<lambda1>": ["ops.math_ops.cast"], "ops.variable_scope.variable_scope": [], "ops.custom_gradient.recompute_grad.inner.grad_wrapper.inner_recompute_grad.transpose": ["<builtin>.NotImplementedError"], "<builtin>.NotImplementedError": [], "ops.custom_gradient.grad_pass_through": ["ops.custom_gradient.custom_gradient", "util.tf_decorator.make_decorator"], "ops.custom_gradient.grad_pass_through._grad_pass_through_op.grad": ["<builtin>.len"]}