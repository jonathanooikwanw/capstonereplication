{"preprocessing.text_test": ["platform.test.main"], "preprocessing.text_test.TestText.test_one_hot": ["test.TestCase.assertGreaterEqual", "test.TestCase.assertEqual", "numpy.max", "<builtin>.len", "test.TestCase.assertLessEqual", "numpy.min", "preprocessing.text.one_hot"], "preprocessing.text.one_hot": [], "<builtin>.len": [], "test.TestCase.assertEqual": [], "numpy.max": [], "test.TestCase.assertLessEqual": [], "numpy.min": [], "test.TestCase.assertGreaterEqual": [], "preprocessing.text_test.TestText.test_tokenizer": ["test.TestCase.assertLess", "test.TestCase.assertEqual", "numpy.max", "numpy.min", "preprocessing.text.Tokenizer"], "preprocessing.text.Tokenizer": [], "test.TestCase.assertLess": [], "preprocessing.text_test.TestText.test_hashing_trick_hash": ["preprocessing.text.hashing_trick", "test.TestCase.assertGreaterEqual", "test.TestCase.assertEqual", "numpy.max", "<builtin>.len", "test.TestCase.assertLessEqual", "numpy.min"], "preprocessing.text.hashing_trick": [], "preprocessing.text_test.TestText.test_hashing_trick_md5": ["preprocessing.text.hashing_trick", "test.TestCase.assertGreaterEqual", "test.TestCase.assertEqual", "numpy.max", "<builtin>.len", "test.TestCase.assertLessEqual", "numpy.min"], "preprocessing.text_test.TestText.test_tokenizer_oov_flag": ["<builtin>.len", "test.TestCase.assertEqual", "preprocessing.text.Tokenizer"], "preprocessing.text_test.TestText.test_sequential_fit": ["test.TestCase.assertEqual", "preprocessing.text.Tokenizer"], "preprocessing.text_test.TestText.test_text_to_word_sequence": ["preprocessing.text.text_to_word_sequence", "test.TestCase.assertEqual"], "preprocessing.text.text_to_word_sequence": [], "preprocessing.text_test.TestText.test_text_to_word_sequence_multichar_split": ["preprocessing.text.text_to_word_sequence", "test.TestCase.assertEqual"], "preprocessing.text_test.TestText.test_text_to_word_sequence_unicode": ["preprocessing.text.text_to_word_sequence", "test.TestCase.assertEqual"], "preprocessing.text_test.TestText.test_text_to_word_sequence_unicode_multichar_split": ["preprocessing.text.text_to_word_sequence", "test.TestCase.assertEqual"], "preprocessing.text_test.TestText.test_tokenizer_unicode": ["<builtin>.len", "test.TestCase.assertEqual", "preprocessing.text.Tokenizer"], "platform.test.main": []}