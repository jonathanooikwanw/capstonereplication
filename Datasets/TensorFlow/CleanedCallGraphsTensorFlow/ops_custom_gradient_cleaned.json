{"ops.custom_gradient": ["util.tf_export.tf_export"], "util.tf_export.tf_export": [], "ops.custom_gradient.custom_gradient": ["util.tf_export.tf_export", "util.tf_decorator.make_decorator", "util.tf_decorator.make_decorator"], "ops.custom_gradient.custom_gradient.<lambda1>": ["util.tf_decorator.make_decorator"], "ops.custom_gradient.Bind.decorator": [], "ops.custom_gradient.custom_gradient.decorated": ["util.tf_decorator.make_decorator", "eager.context.executing_eagerly", "eager.context.executing_eagerly"], "eager.context.executing_eagerly": [], "ops.custom_gradient._eager_mode_decorator": ["util.tf_inspect.getfullargspec", "<builtin>.all", "eager.tape.VariableWatcher", "eager.tape.record_operation", "<builtin>.list", "<builtin>.set", "eager.tape.record_operation", "framework.ops.convert_to_tensor", "ops.gen_array_ops.identity", "<builtin>.TypeError", "<builtin>.len", "util.nest.pack_sequence_as", "util.nest.pack_sequence_as", "util.nest.pack_sequence_as", "util.nest.flatten"], "ops.custom_gradient._graph_mode_decorator": ["util.nest.map_structure", "util.nest.map_structure", "ops.resource_variable_ops.is_resource_variable", "<builtin>.frozenset", "eager.tape.VariableWatcher", "<builtin>.zip", "<builtin>.hasattr", "util.nest.flatten", "util.tf_inspect.getfullargspec", "<builtin>.sorted", "ops.variable_scope.get_variable_scope", "util.nest.pack_sequence_as", "util.nest.pack_sequence_as", "<builtin>.TypeError", "util.nest.pack_sequence_as", "framework.ops.RegisterGradient", "<builtin>.enumerate", "framework.ops.RegisterGradient", "<builtin>.ValueError", "framework.ops.get_default_graph", "<builtin>.set", "framework.ops.convert_to_tensor", "framework.ops.convert_to_tensor", "ops.handle_data_util.copy_handle_data", "ops.array_ops.identity_n", "eager.tape.record_operation", "<builtin>.len", "platform.tf_logging.warning", "<builtin>.getattr"], "util.tf_decorator.make_decorator": [], "ops.custom_gradient.Bind.decorator.<lambda1>": ["platform.tf_logging.warning"], "ops.custom_gradient.Bind.__init__": [], "ops.custom_gradient.Bind.__get__": ["util.tf_decorator.make_decorator", "util.tf_decorator.make_decorator"], "ops.custom_gradient.Bind.__call__": [], "ops.custom_gradient.get_variable_by_name": ["<builtin>.filter", "<builtin>.ValueError", "framework.ops.get_collection", "<builtin>.list", "<builtin>.len"], "framework.ops.get_collection": [], "ops.custom_gradient.get_variable_by_name._filter_fn": [], "<builtin>.filter": [], "<builtin>.list": [], "<builtin>.len": [], "<builtin>.ValueError": [], "ops.custom_gradient._get_dependent_variables": ["framework.ops.get_collection", "util.nest.map_structure", "ops.op_selector.get_backward_walk_ops"], "util.nest.map_structure": [], "ops.op_selector.get_backward_walk_ops": [], "ops.custom_gradient.generate_name": ["framework.ops.uid"], "framework.ops.uid": [], "ops.variable_scope.get_variable_scope": [], "<builtin>.set": [], "eager.tape.VariableWatcher": [], "ops.custom_gradient.recompute_grad.inner": ["eager.tape.stop_recording", "ops.variable_scope.get_variable_scope"], "ops.custom_gradient.grad_pass_through._grad_pass_through_op": [], "ops.custom_gradient.recompute_grad.inner.grad_wrapper.inner_recompute_grad": ["ops.math_ops.reduce_max", "<builtin>.float", "util.nest.map_structure", "eager.backprop.GradientTape", "<builtin>.len", "ops.variable_scope.variable_scope", "ops.array_ops.reshape", "<builtin>.list", "ops.math_ops.cast", "eager.context.executing_eagerly", "ops.array_ops.where_v2"], "util.nest.flatten": [], "ops.resource_variable_ops.is_resource_variable": [], "<builtin>.TypeError": [], "<builtin>.frozenset": [], "<builtin>.getattr": [], "ops.custom_gradient._graph_mode_decorator.<lambda1>": [], "<builtin>.sorted": [], "util.tf_inspect.getfullargspec": [], "platform.tf_logging.warning": [], "ops.custom_gradient._graph_mode_decorator.tape_grad_fn": ["<builtin>.len", "<builtin>.ValueError", "util.nest.flatten"], "framework.ops.RegisterGradient": [], "ops.custom_gradient._graph_mode_decorator.internal_grad_fn": ["util.nest.flatten"], "framework.ops.get_default_graph": [], "ops.array_ops.identity_n": [], "framework.ops.convert_to_tensor": [], "<builtin>.enumerate": [], "<builtin>.hasattr": [], "eager.tape.record_operation": [], "<builtin>.zip": [], "ops.handle_data_util.copy_handle_data": [], "util.nest.pack_sequence_as": [], "<builtin>.all": [], "ops.gen_array_ops.identity": [], "ops.custom_gradient._eager_mode_decorator.actual_grad_fn": ["<builtin>.len", "<builtin>.ValueError", "util.nest.flatten"], "ops.custom_gradient.recompute_grad": ["util.tf_decorator.make_decorator", "util.tf_decorator.make_decorator"], "eager.tape.stop_recording": [], "ops.custom_gradient.recompute_grad.inner.grad_wrapper": ["util.tf_decorator.make_decorator", "util.tf_decorator.make_decorator"], "eager.backprop.GradientTape": [], "ops.array_ops.reshape": [], "ops.math_ops.reduce_max": [], "ops.math_ops.cast": [], "<builtin>.float": [], "ops.array_ops.where_v2": [], "ops.custom_gradient.recompute_grad.inner.grad_wrapper.inner_recompute_grad.<lambda1>": ["ops.math_ops.cast"], "ops.variable_scope.variable_scope": [], "ops.custom_gradient.recompute_grad.inner.grad_wrapper.inner_recompute_grad.transpose": ["<builtin>.NotImplementedError"], "<builtin>.NotImplementedError": [], "ops.custom_gradient.grad_pass_through": ["util.tf_decorator.make_decorator", "util.tf_decorator.make_decorator"], "ops.custom_gradient.grad_pass_through._grad_pass_through_op.grad": ["<builtin>.len"]}