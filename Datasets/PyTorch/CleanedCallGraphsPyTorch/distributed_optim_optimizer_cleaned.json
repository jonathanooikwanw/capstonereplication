{"optimizer": ["logging.getLogger", "torch.jit.script"], "logging.getLogger": [], "optimizer._ScriptLocalOptimizerInterface.step": [], "threading.Lock": [], "optimizer._ScriptLocalOptimizer": ["torch.jit.export", "threading.Lock"], "optimizer._ScriptLocalOptimizer.__init__": ["<builtin>.super"], "<builtin>.super": [], "torch.jit.export": [], "optimizer._ScriptLocalOptimizer.step": ["torch.distributed.autograd.get_gradients"], "torch.distributed.autograd.get_gradients": [], "optimizer._LocalOptimizer": ["threading.Lock"], "optimizer._LocalOptimizer.__init__": [], "optimizer._LocalOptimizer.step": ["torch.distributed.autograd.get_gradients"], "optimizer._new_local_optimizer": ["torch.distributed.rpc.RRef", "optimizer._LocalOptimizer.__init__"], "torch.distributed.rpc.RRef": [], "optimizer._local_optimizer_step": [], "optimizer._new_script_local_optimizer": ["torch.distributed.rpc.RRef", "torch.jit.script", "optimizer._ScriptLocalOptimizer.__init__"], "torch.jit.script": [], "optimizer._script_local_optimizer_step": [], "optimizer._wait_for_all": [], "optimizer.DistributedOptimizer.__init__": ["torch.distributed.optim.functional_optim_map.get", "collections.defaultdict", "torch.distributed.rpc.rpc_async", "optimizer._wait_for_all"], "collections.defaultdict": [], "torch.distributed.optim.functional_optim_map.get": [], "torch.distributed.rpc.rpc_async": [], "optimizer.DistributedOptimizer.step": ["torch.distributed.autograd._is_valid_context", "torch.distributed.rpc.rpc_async", "optimizer._wait_for_all"], "torch.distributed.autograd._is_valid_context": []}