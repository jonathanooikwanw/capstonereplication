{"adam": [], "adam.Adam.__init__": ["<builtin>.ValueError", "<builtin>.super", "<builtin>.dict"], "<builtin>.ValueError": [], "<builtin>.dict": [], "<builtin>.super": [], "adam.Adam.__setstate__": ["optimizer.Optimizer.param_groups.setdefault", "<builtin>.super"], "optimizer.Optimizer.param_groups.setdefault": [], "torch.no_grad": [], "adam.Adam": ["torch.no_grad"], "adam.Adam.step": ["torch.zeros_like", "<builtin>.len", "_functional.adam", "<builtin>.RuntimeError", "torch.enable_grad"], "torch.enable_grad": [], "<builtin>.RuntimeError": [], "<builtin>.len": [], "torch.zeros_like": [], "_functional.adam": []}