{"reinforcement_learning_rpc_test": [], "reinforcement_learning_rpc_test._call_method": [], "reinforcement_learning_rpc_test._remote_method": ["torch.distributed.rpc.rpc_sync", "<builtin>.list"], "<builtin>.list": [], "torch.distributed.rpc.rpc_sync": [], "reinforcement_learning_rpc_test.Policy.__init__": ["torch.nn.Dropout", "<builtin>.super", "torch.nn.Linear"], "<builtin>.super": [], "torch.nn.Linear": [], "torch.nn.Dropout": [], "reinforcement_learning_rpc_test.Policy.forward": ["torch.nn.functional.softmax", "torch.nn.functional.relu"], "torch.nn.functional.relu": [], "torch.nn.functional.softmax": [], "reinforcement_learning_rpc_test.DummyEnv.__init__": [], "reinforcement_learning_rpc_test.DummyEnv.seed": ["torch.manual_seed"], "torch.manual_seed": [], "reinforcement_learning_rpc_test.DummyEnv.reset": ["torch.randn"], "torch.randn": [], "reinforcement_learning_rpc_test.DummyEnv.step": ["torch.rand", "torch.randn"], "torch.rand": [], "reinforcement_learning_rpc_test.Observer.__init__": ["reinforcement_learning_rpc_test.DummyEnv.seed", "torch.distributed.rpc.get_worker_info", "reinforcement_learning_rpc_test.DummyEnv.__init__"], "torch.distributed.rpc.get_worker_info": [], "reinforcement_learning_rpc_test.Observer.run_episode": ["reinforcement_learning_rpc_test.DummyEnv.step", "reinforcement_learning_rpc_test.DummyEnv.reset", "reinforcement_learning_rpc_test._remote_method", "<builtin>.range"], "<builtin>.range": [], "reinforcement_learning_rpc_test.Agent.__init__": ["torch.distributed.rpc.remote", "numpy.finfo", "reinforcement_learning_rpc_test.DummyEnv.__init__", "torch.distributed.rpc.get_worker_info", "torch.optim.Adam", "torch.distributed.rpc.RRef", "torch.nn.Module.parameters", "torch.testing._internal.dist_utils.worker_name", "reinforcement_learning_rpc_test.Policy.__init__", "<builtin>.range"], "torch.distributed.rpc.RRef": [], "torch.nn.Module.parameters": [], "torch.optim.Adam": [], "numpy.finfo": [], "torch.testing._internal.dist_utils.worker_name": [], "torch.distributed.rpc.remote": [], "reinforcement_learning_rpc_test.Agent.select_action": ["reinforcement_learning_rpc_test.Policy.__init__", "torch.distributions.Categorical"], "torch.distributions.Categorical": [], "reinforcement_learning_rpc_test.Agent.report_reward": [], "reinforcement_learning_rpc_test.Agent.run_episode": ["torch.distributed.rpc.rpc_async"], "torch.distributed.rpc.rpc_async": [], "reinforcement_learning_rpc_test.Agent.finish_episode": ["<builtin>.sum", "<builtin>.min", "torch.cat", "torch.tensor", "<builtin>.zip"], "<builtin>.sum": [], "<builtin>.min": [], "torch.tensor": [], "<builtin>.zip": [], "torch.cat": [], "reinforcement_learning_rpc_test.run_agent": ["reinforcement_learning_rpc_test.Agent.finish_episode", "<builtin>.print", "reinforcement_learning_rpc_test.Agent.run_episode", "itertools.count"], "itertools.count": [], "<builtin>.print": [], "torch.testing._internal.dist_utils.dist_init": [], "reinforcement_learning_rpc_test.ReinforcementLearningRpcTest": ["torch.testing._internal.dist_utils.dist_init"], "reinforcement_learning_rpc_test.ReinforcementLearningRpcTest.test_rl_rpc": ["reinforcement_learning_rpc_test.run_agent", "torch.testing._internal.distributed.rpc.rpc_agent_test_fixture.RpcAgentTestFixture.assertGreater", "<builtin>.int", "torch.distributed.rpc.shutdown", "torch.testing._internal.dist_utils.worker_name", "torch.distributed.rpc.init_rpc", "reinforcement_learning_rpc_test.Agent.__init__"], "torch.distributed.rpc.init_rpc": [], "<builtin>.int": [], "torch.testing._internal.distributed.rpc.rpc_agent_test_fixture.RpcAgentTestFixture.assertGreater": [], "torch.distributed.rpc.shutdown": []}