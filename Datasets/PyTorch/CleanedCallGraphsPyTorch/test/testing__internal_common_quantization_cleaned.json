{"common_quantization": ["torch.nn.CrossEntropyLoss", "unittest.skipIf"], "common_quantization.NodeSpec.__init__": [], "common_quantization.NodeSpec.call_function": ["common_quantization.NodeSpec.__init__"], "common_quantization.NodeSpec.call_method": ["common_quantization.NodeSpec.__init__"], "common_quantization.NodeSpec.call_module": ["common_quantization.NodeSpec.__init__"], "common_quantization.NodeSpec.__hash__": ["<builtin>.hash"], "<builtin>.hash": [], "common_quantization.NodeSpec.__eq__": ["<builtin>.isinstance"], "<builtin>.isinstance": [], "common_quantization.NodeSpec.__repr__": ["<builtin>.repr"], "<builtin>.repr": [], "common_quantization.test_only_eval_fn": [], "torch.nn.CrossEntropyLoss": [], "common_quantization.test_only_train_fn": ["torch.max", "torch.optim.Adam", "<builtin>.range"], "torch.optim.Adam": [], "<builtin>.range": [], "torch.max": [], "common_quantization.AverageMeter.__init__": ["common_quantization.AverageMeter.reset"], "common_quantization.AverageMeter.reset": [], "common_quantization.AverageMeter.update": [], "common_quantization.AverageMeter.__str__": [], "common_quantization.accuracy": ["<builtin>.max", "torch.no_grad"], "torch.no_grad": [], "<builtin>.max": [], "common_quantization.train_one_epoch": ["time.time", "common_quantization.accuracy", "<builtin>.print"], "time.time": [], "<builtin>.print": [], "common_quantization.ddp_setup": ["torch.distributed.init_process_group"], "torch.distributed.init_process_group": [], "common_quantization.ddp_cleanup": ["torch.distributed.destroy_process_group"], "torch.distributed.destroy_process_group": [], "common_quantization.run_ddp": ["torch.optim.SGD", "common_quantization.train_one_epoch", "torch.nn.parallel.DistributedDataParallel", "common_quantization.ddp_setup", "common_quantization.ddp_cleanup"], "torch.nn.parallel.DistributedDataParallel": [], "torch.optim.SGD": [], "common_quantization.convert_dynamic": ["torch.quantization.quantization_mappings.get_default_dynamic_quant_module_mappings", "torch.quantization.convert"], "torch.quantization.quantization_mappings.get_default_dynamic_quant_module_mappings": [], "torch.quantization.convert": [], "common_quantization.prepare_dynamic": ["torch.quantization.propagate_qconfig_"], "torch.quantization.propagate_qconfig_": [], "common_quantization._make_conv_test_input": ["<builtin>.len", "torch.randint", "torch.quantize_per_channel", "torch.tensor", "torch.quantize_per_tensor"], "torch.randint": [], "torch.quantize_per_tensor": [], "<builtin>.len": [], "torch.tensor": [], "torch.quantize_per_channel": [], "common_quantization.skipIfNoFBGEMM": ["functools.wraps", "<builtin>.isinstance"], "functools.wraps": [], "common_quantization.skipIfNoFBGEMM.wrapper": ["unittest.SkipTest"], "unittest.SkipTest": [], "common_quantization.skipIfNoQNNPACK": ["functools.wraps", "<builtin>.isinstance"], "common_quantization.skipIfNoQNNPACK.wrapper": ["unittest.SkipTest"], "unittest.skipIf": [], "common_quantization.get_script_module": ["torch.jit.trace", "torch.jit.script"], "torch.jit.trace": [], "torch.jit.script": [], "common_quantization.lengths_to_offsets": ["numpy.zeros", "torch.from_numpy", "numpy.cumsum"], "numpy.zeros": [], "numpy.cumsum": [], "torch.from_numpy": [], "common_quantization.QuantizationTestCase.setUp": ["torch.randint", "<builtin>.range", "torch.rand", "<builtin>.super"], "<builtin>.super": [], "torch.rand": [], "common_quantization.QuantizationTestCase.checkNoPrepModules": ["<builtin>.hasattr", "torch.testing._internal.common_utils.TestCase.assertFalse"], "<builtin>.hasattr": [], "torch.testing._internal.common_utils.TestCase.assertFalse": [], "common_quantization.QuantizationTestCase.checkNoQconfig": ["common_quantization.QuantizationTestCase.checkNoQconfig", "<builtin>.hasattr", "torch.testing._internal.common_utils.TestCase.assertFalse"], "common_quantization.QuantizationTestCase.checkHasPrepModules": ["<builtin>.hasattr", "torch.testing._internal.common_utils.TestCase.assertTrue"], "torch.testing._internal.common_utils.TestCase.assertTrue": [], "common_quantization.QuantizationTestCase.checkObservers": ["torch.testing._internal.common_utils.TestCase.assertTrue", "<builtin>.str", "torch.quantization.quantization_mappings.get_default_qat_module_mappings", "torch.quantization.quantization_mappings.get_default_qconfig_propagation_list", "<builtin>.type", "<builtin>.hasattr", "<builtin>.isinstance", "common_quantization.QuantizationTestCase.checkObservers.is_leaf_module", "common_quantization.QuantizationTestCase.checkObservers"], "torch.quantization.quantization_mappings.get_default_qconfig_propagation_list": [], "common_quantization.QuantizationTestCase.checkObservers.is_leaf_module": [], "<builtin>.type": [], "<builtin>.str": [], "torch.quantization.quantization_mappings.get_default_qat_module_mappings": [], "common_quantization.QuantizationTestCase.checkQuantDequant": ["torch.testing._internal.common_utils.TestCase.assertEqual", "<builtin>.type"], "torch.testing._internal.common_utils.TestCase.assertEqual": [], "common_quantization.QuantizationTestCase.checkWrappedQuantizedLinear": ["common_quantization.QuantizationTestCase.checkQuantDequant", "torch.testing._internal.common_utils.TestCase.assertEqual", "<builtin>.type"], "common_quantization.QuantizationTestCase.checkQuantizedLinear": ["torch.testing._internal.common_utils.TestCase.assertEqual", "<builtin>.type"], "common_quantization.QuantizationTestCase.checkDynamicQuantizedLinear": ["torch.testing._internal.common_utils.TestCase.assertEqual", "<builtin>.type"], "common_quantization.QuantizationTestCase.check_eager_serialization": ["io.BytesIO", "torch.save", "torch.load", "common_quantization.QuantizationTestCase.check_eager_serialization.check_outputs"], "io.BytesIO": [], "torch.save": [], "torch.load": [], "common_quantization.QuantizationTestCase.check_eager_serialization.check_outputs": ["torch.testing._internal.common_utils.TestCase.assertEqual", "<builtin>.isinstance"], "common_quantization.QuantizationTestCase.check_weight_bias_api": ["<builtin>.set", "torch.testing._internal.common_utils.TestCase.assertEqual"], "<builtin>.set": [], "common_quantization.QuantizationTestCase.checkDynamicQuantizedLSTM": ["torch.testing._internal.common_utils.TestCase.assertEqual", "<builtin>.type"], "common_quantization.QuantizationTestCase.checkLinear": ["torch.testing._internal.common_utils.TestCase.assertEqual", "<builtin>.type"], "common_quantization.QuantizationTestCase.checkDynamicQuantizedModule": ["<builtin>.hasattr", "torch.testing._internal.common_utils.TestCase.assertEqual", "<builtin>.type"], "common_quantization.QuantizationTestCase.checkScriptable": ["torch.jit.script", "common_quantization.QuantizationTestCase._checkScriptable", "torch.jit.trace"], "common_quantization.QuantizationTestCase._checkScriptable": ["io.BytesIO", "common_quantization.QuantizationTestCase._checkModuleCorrectnessAgainstOrig", "torch.jit.load", "torch.jit.save"], "common_quantization.QuantizationTestCase._checkModuleCorrectnessAgainstOrig": ["torch.testing._internal.common_utils.TestCase.assertEqual"], "torch.jit.save": [], "torch.jit.load": [], "common_quantization.QuantizationTestCase.checkGraphModeOp": ["torch.quantization.get_default_qconfig", "<builtin>.str", "torch.quantization.quantize_jit", "common_quantization.get_script_module", "copy.deepcopy", "<builtin>.print", "torch.testing.FileCheck", "torch.testing._internal.common_utils.TestCase.assertEqual", "torch.quantization.quantize_dynamic_jit"], "torch.quantization.get_default_qconfig": [], "torch.quantization.quantize_dynamic_jit": [], "copy.deepcopy": [], "torch.quantization.quantize_jit": [], "torch.testing.FileCheck": [], "common_quantization.QuantizationTestCase.checkGraphModuleNodes": ["common_quantization.NodeSpec.__init__", "<builtin>.dict", "<builtin>.len", "<builtin>.str", "common_quantization.QuantizationTestCase.printGraphModule", "<builtin>.type", "torch.testing._internal.common_utils.TestCase.assertTrue"], "<builtin>.dict": [], "common_quantization.QuantizationTestCase.printGraphModule": ["<builtin>.repr", "<builtin>.dict", "<builtin>.type", "<builtin>.print", "<builtin>.map"], "<builtin>.map": [], "common_quantization.QuantizationTestCase.assert_types_for_matched_subgraph_pairs": ["common_quantization.QuantizationTestCase.assert_types_for_matched_subgraph_pairs._get_underlying_op_type", "torch.testing._internal.common_utils.TestCase.assertTrue", "<builtin>.len"], "common_quantization.QuantizationTestCase.assert_types_for_matched_subgraph_pairs._get_underlying_op_type": ["<builtin>.getattr", "<builtin>.type"], "<builtin>.getattr": [], "common_quantization.QuantizationTestCase.assert_ns_compare_dict_valid": ["<builtin>.range", "<builtin>.len", "<builtin>.type", "<builtin>.isinstance", "torch.testing._internal.common_utils.TestCase.assertTrue"], "common_quantization.QuantizationTestCase.checkGraphModeFxOp": ["torch.quantization.get_default_qconfig", "torch.quantization.quantize_fx.convert_fx", "common_quantization.QuantizationTestCase.printGraphModule", "copy.deepcopy", "torch.quantization.quantize_fx.prepare_qat_fx", "<builtin>.type", "torch.quantization.quantize_fx.prepare_fx", "common_quantization.QuantizationTestCase.checkGraphModuleNodes", "<builtin>.print", "torch.quantization.get_default_qat_qconfig"], "torch.quantization.get_default_qat_qconfig": [], "torch.quantization.quantize_fx.prepare_fx": [], "torch.quantization.quantize_fx.prepare_qat_fx": [], "torch.quantization.quantize_fx.convert_fx": [], "common_quantization.QuantizationTestCase.checkEmbeddingSerialization": ["common_quantization.QuantizationTestCase.check_eager_serialization", "torch.nn.quantized.EmbeddingBag.from_float", "io.BytesIO", "torch.save", "torch.nn.EmbeddingBag", "torch.testing._internal.common_utils.TestCase.assertTrue", "common_quantization.QuantizationTestCase.checkScriptable", "common_quantization.prepare_dynamic", "torch.nn.quantized.Embedding", "torch.testing._internal.common_utils.TestCase.assertEqual", "torch.quantization.PerChannelMinMaxObserver.with_args", "torch.quantization.QConfigDynamic", "torch.ops.quantized.embedding_bag_unpack", "<builtin>.str", "torch.load", "torch.nn.quantized.EmbeddingBag", "torch.nn.quantized.Embedding.from_float", "<builtin>.isinstance", "torch.nn.Embedding"], "torch.ops.quantized.embedding_bag_unpack": [], "torch.nn.quantized.EmbeddingBag": [], "torch.nn.quantized.Embedding": [], "torch.nn.EmbeddingBag": [], "torch.nn.Embedding": [], "torch.quantization.PerChannelMinMaxObserver.with_args": [], "torch.quantization.QConfigDynamic": [], "torch.nn.quantized.EmbeddingBag.from_float": [], "torch.nn.quantized.Embedding.from_float": [], "common_quantization.QuantizationLiteTestCase.setUp": ["<builtin>.super"], "common_quantization.QuantizationLiteTestCase._create_quantized_model": ["torch.quantization.get_default_qconfig", "torch.testing._internal.common_quantized.override_quantized_engine", "torch.quantization.quantize"], "torch.testing._internal.common_quantized.override_quantized_engine": [], "torch.quantization.quantize": [], "common_quantization.QuantizationLiteTestCase._compare_script_and_mobile": ["<builtin>.range", "torch.testing._internal.common_quantized.override_quantized_engine", "io.BytesIO", "torch.jit.script", "torch.testing.assert_allclose", "torch.jit.mobile._load_for_lite_interpreter"], "torch.jit.mobile._load_for_lite_interpreter": [], "torch.testing.assert_allclose": [], "common_quantization.SingleLayerLinearModel.__init__": ["torch.nn.Linear", "<builtin>.super"], "torch.nn.Linear": [], "common_quantization.SingleLayerLinearModel.forward": [], "common_quantization.AnnotatedSingleLayerLinearModel.__init__": ["torch.quantization.get_default_qconfig", "torch.quantization.QuantWrapper", "torch.nn.Linear", "<builtin>.super"], "torch.quantization.QuantWrapper": [], "common_quantization.AnnotatedSingleLayerLinearModel.forward": [], "common_quantization.SingleLayerLinearDynamicModel.__init__": ["torch.quantization.get_default_qconfig", "torch.nn.Linear", "<builtin>.super"], "common_quantization.SingleLayerLinearDynamicModel.forward": [], "common_quantization.LinearAddModel.__init__": ["torch.nn.Linear", "<builtin>.super"], "common_quantization.LinearAddModel.forward": ["torch.add"], "torch.add": [], "common_quantization.RNNDynamicModel.__init__": ["torch.nn.LSTM", "torch.nn.GRU", "<builtin>.super"], "torch.nn.GRU": [], "torch.nn.LSTM": [], "common_quantization.RNNDynamicModel.forward": [], "common_quantization.RNNCellDynamicModel.__init__": ["torch.nn.RNNCell", "torch.nn.LSTMCell", "torch.nn.GRUCell", "<builtin>.super"], "torch.nn.GRUCell": [], "torch.nn.LSTMCell": [], "torch.nn.RNNCell": [], "common_quantization.RNNCellDynamicModel.forward": [], "common_quantization.LSTMwithHiddenDynamicModel.__init__": ["torch.quantization.get_default_qconfig", "torch.nn.LSTM", "<builtin>.super"], "common_quantization.LSTMwithHiddenDynamicModel.forward": [], "common_quantization.ConvModel.__init__": ["torch.nn.Conv2d", "<builtin>.super"], "torch.nn.Conv2d": [], "common_quantization.ConvModel.forward": [], "common_quantization.ConvTransposeModel.__init__": ["torch.nn.ConvTranspose2d", "<builtin>.super"], "torch.nn.ConvTranspose2d": [], "common_quantization.ConvTransposeModel.forward": [], "common_quantization.AnnotatedConvModel.__init__": ["torch.quantization.get_default_qconfig", "torch.quantization.DeQuantStub", "torch.quantization.QuantStub", "<builtin>.super", "torch.nn.Conv2d"], "torch.quantization.QuantStub": [], "torch.quantization.DeQuantStub": [], "common_quantization.AnnotatedConvModel.forward": [], "common_quantization.AnnotatedConvTransposeModel.__init__": ["torch.quantization.get_default_qconfig", "torch.quantization.DeQuantStub", "torch.quantization.QuantStub", "<builtin>.super", "torch.nn.ConvTranspose2d"], "common_quantization.AnnotatedConvTransposeModel.forward": [], "common_quantization.ConvBnModel.__init__": ["torch.nn.Conv2d", "torch.nn.BatchNorm2d", "<builtin>.super"], "torch.nn.BatchNorm2d": [], "common_quantization.ConvBnModel.forward": [], "common_quantization.AnnotatedConvBnModel.__init__": ["torch.quantization.DeQuantStub", "torch.quantization.QuantStub", "torch.nn.BatchNorm2d", "<builtin>.super", "torch.nn.Conv2d"], "common_quantization.AnnotatedConvBnModel.forward": [], "common_quantization.ConvBnReLUModel.__init__": ["torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "<builtin>.super"], "torch.nn.ReLU": [], "common_quantization.ConvBnReLUModel.forward": [], "common_quantization.AnnotatedConvBnReLUModel.__init__": ["torch.quantization.get_default_qconfig", "torch.quantization.DeQuantStub", "torch.quantization.QuantStub", "torch.nn.BatchNorm2d", "<builtin>.super", "torch.nn.ReLU", "torch.nn.Conv2d"], "common_quantization.AnnotatedConvBnReLUModel.forward": [], "common_quantization.AnnotatedConvBnReLUModel.fuse_model": ["torch.quantization.fuse_modules"], "torch.quantization.fuse_modules": [], "common_quantization.TwoLayerConvModel.__init__": ["torch.nn.Conv2d", "<builtin>.super"], "common_quantization.TwoLayerConvModel.forward": [], "common_quantization.TwoLayerLinearModel.__init__": ["torch.nn.Linear", "<builtin>.super"], "common_quantization.TwoLayerLinearModel.forward": ["common_quantization.TwoLayerLinearModel.__init__"], "common_quantization.LinearModelWithSubmodule.__init__": ["torch.nn.Linear", "common_quantization.TwoLayerLinearModel.__init__", "<builtin>.super"], "common_quantization.LinearModelWithSubmodule.forward": ["common_quantization.TwoLayerLinearModel.__init__"], "common_quantization.AnnotatedTwoLayerLinearModel.__init__": ["torch.nn.Linear", "torch.quantization.QuantWrapper", "torch.quantization.get_default_qconfig", "<builtin>.super"], "common_quantization.AnnotatedTwoLayerLinearModel.forward": [], "common_quantization.ActivationsTestModel.__init__": ["torch.quantization.get_default_qconfig", "torch.quantization.DeQuantStub", "torch.quantization.QuantStub", "<builtin>.super", "torch.nn.Hardswish", "torch.nn.ELU"], "torch.nn.Hardswish": [], "torch.nn.ELU": [], "common_quantization.ActivationsTestModel.forward": [], "common_quantization.LinearReluModel.__init__": ["torch.nn.Linear", "torch.nn.ReLU", "<builtin>.super"], "common_quantization.LinearReluModel.forward": [], "common_quantization.LinearReluLinearModel.__init__": ["torch.nn.Linear", "torch.nn.ReLU", "<builtin>.super"], "common_quantization.LinearReluLinearModel.forward": [], "common_quantization.LinearReluAddModel.__init__": ["torch.nn.Linear", "torch.nn.ReLU", "<builtin>.super"], "common_quantization.LinearReluAddModel.forward": ["torch.nn.ReLU", "torch.add"], "common_quantization.ConvReluModel.__init__": ["torch.nn.ReLU", "torch.nn.Conv2d", "<builtin>.super"], "common_quantization.ConvReluModel.forward": [], "common_quantization.ConvReluConvModel.__init__": ["torch.nn.ReLU", "torch.nn.Conv2d", "<builtin>.super"], "common_quantization.ConvReluConvModel.forward": [], "common_quantization.ConvReluAddModel.__init__": ["torch.nn.ReLU", "torch.nn.Conv2d", "<builtin>.super"], "common_quantization.ConvReluAddModel.forward": ["torch.nn.ReLU", "torch.add"], "common_quantization.NormalizationTestModel.__init__": ["torch.quantization.QuantStub", "<builtin>.super", "torch.nn.LayerNorm", "torch.nn.InstanceNorm3d", "torch.nn.GroupNorm", "torch.nn.Linear", "torch.nn.InstanceNorm1d", "torch.nn.InstanceNorm2d"], "torch.nn.LayerNorm": [], "torch.nn.GroupNorm": [], "torch.nn.InstanceNorm1d": [], "torch.nn.InstanceNorm2d": [], "torch.nn.InstanceNorm3d": [], "common_quantization.NormalizationTestModel.forward": [], "common_quantization.NestedModel.__init__": ["common_quantization.LinearReluModel.__init__", "torch.nn.Linear", "common_quantization.TwoLayerLinearModel.__init__", "<builtin>.super"], "common_quantization.NestedModel.forward": ["common_quantization.LinearReluModel.__init__", "common_quantization.TwoLayerLinearModel.__init__"], "common_quantization.AnnotatedNestedModel.__init__": ["<builtin>.super", "common_quantization.LinearReluModel.__init__", "torch.quantization.QuantWrapper", "torch.nn.Linear", "common_quantization.TwoLayerLinearModel.__init__"], "common_quantization.AnnotatedNestedModel.forward": ["common_quantization.LinearReluModel.__init__", "common_quantization.TwoLayerLinearModel.__init__"], "common_quantization.AnnotatedSubNestedModel.__init__": ["<builtin>.super", "common_quantization.LinearReluModel.__init__", "torch.nn.Linear", "torch.quantization.QuantWrapper", "common_quantization.TwoLayerLinearModel.__init__"], "common_quantization.AnnotatedSubNestedModel.forward": ["common_quantization.LinearReluModel.__init__"], "common_quantization.AnnotatedCustomConfigNestedModel.__init__": ["<builtin>.super", "common_quantization.LinearReluModel.__init__", "torch.quantization.default_observer.with_args", "torch.quantization.QuantWrapper", "torch.nn.Linear", "common_quantization.TwoLayerLinearModel.__init__", "torch.quantization.QConfig"], "torch.quantization.default_observer.with_args": [], "torch.quantization.QConfig": [], "common_quantization.AnnotatedCustomConfigNestedModel.forward": ["common_quantization.LinearReluModel.__init__", "common_quantization.TwoLayerLinearModel.__init__"], "common_quantization.QuantSubModel.__init__": ["<builtin>.super", "common_quantization.LinearReluModel.__init__", "torch.nn.Linear", "torch.quantization.QuantWrapper", "common_quantization.TwoLayerLinearModel.__init__"], "common_quantization.QuantSubModel.forward": ["common_quantization.LinearReluModel.__init__"], "common_quantization.InnerModule.__init__": ["torch.nn.Linear", "torch.nn.ReLU", "<builtin>.super"], "common_quantization.InnerModule.forward": ["common_quantization.TwoLayerLinearModel.__init__"], "common_quantization.InnerModule.fuse_modules": ["<builtin>.len", "torch.nn.Module.named_children", "<builtin>.list", "<builtin>.enumerate", "torch.quantization.fuse_modules", "<builtin>.isinstance"], "torch.nn.Module.named_children": [], "<builtin>.list": [], "<builtin>.enumerate": [], "common_quantization.FunctionalLinear.__init__": ["torch.zeros", "torch.rand", "<builtin>.super"], "torch.zeros": [], "common_quantization.FunctionalLinear.forward": ["torch.nn.functional.linear"], "torch.nn.functional.linear": [], "common_quantization.SingleLayerFunctionalLinearModel.__init__": ["common_quantization.FunctionalLinear.__init__", "<builtin>.super"], "common_quantization.SingleLayerFunctionalLinearModel.forward": ["common_quantization.FunctionalLinear.__init__"], "common_quantization.TwoLayerFunctionalLinearModel.__init__": ["common_quantization.FunctionalLinear.__init__", "<builtin>.super"], "common_quantization.TwoLayerFunctionalLinearModel.forward": ["common_quantization.FunctionalLinear.__init__"], "common_quantization.FunctionalLinearAddModel.__init__": ["common_quantization.FunctionalLinear.__init__", "<builtin>.super"], "common_quantization.FunctionalLinearAddModel.forward": ["torch.add", "common_quantization.FunctionalLinear.__init__"], "common_quantization.FunctionalLinearReluModel.__init__": ["common_quantization.FunctionalLinear.__init__", "<builtin>.super"], "common_quantization.FunctionalLinearReluModel.forward": ["torch.nn.functional.relu", "common_quantization.FunctionalLinear.__init__"], "torch.nn.functional.relu": [], "common_quantization.FunctionalLinearReluLinearModel.__init__": ["torch.nn.ReLU", "common_quantization.FunctionalLinear.__init__", "<builtin>.super"], "common_quantization.FunctionalLinearReluLinearModel.forward": ["common_quantization.FunctionalLinear.__init__"], "common_quantization.FunctionalConv2d.__init__": ["torch.rand", "<builtin>.super"], "common_quantization.FunctionalConv2d.forward": ["torch.nn.functional.conv2d"], "torch.nn.functional.conv2d": [], "common_quantization.SingleLayerFunctionalConvModel.__init__": ["common_quantization.FunctionalConv2d.__init__", "<builtin>.super"], "common_quantization.SingleLayerFunctionalConvModel.forward": ["common_quantization.FunctionalConv2d.__init__"], "common_quantization.TwoLayerFunctionalConvModel.__init__": ["common_quantization.FunctionalConv2d.__init__", "<builtin>.super"], "common_quantization.TwoLayerFunctionalConvModel.forward": ["common_quantization.FunctionalConv2d.__init__"], "common_quantization.FunctionalConvReluModel.__init__": ["common_quantization.FunctionalConv2d.__init__", "<builtin>.super"], "common_quantization.FunctionalConvReluModel.forward": ["torch.nn.functional.relu", "common_quantization.FunctionalConv2d.__init__"], "common_quantization.FunctionalConvReluConvModel.__init__": ["torch.nn.ReLU", "common_quantization.FunctionalConv2d.__init__", "<builtin>.super"], "common_quantization.FunctionalConvReluConvModel.forward": ["common_quantization.FunctionalConv2d.__init__"], "common_quantization.SkipQuantModel.__init__": ["torch.nn.Linear", "common_quantization.TwoLayerLinearModel.__init__", "<builtin>.super"], "common_quantization.SkipQuantModel.forward": ["common_quantization.TwoLayerLinearModel.__init__"], "common_quantization.SkipQuantModel.fuse_modules": ["torch.nn.Module.fuse_modules"], "torch.nn.Module.fuse_modules": [], "common_quantization.AnnotatedSkipQuantModel.__init__": ["torch.quantization.get_default_qconfig", "<builtin>.super", "torch.nn.Linear", "torch.quantization.QuantWrapper", "common_quantization.TwoLayerLinearModel.__init__"], "common_quantization.AnnotatedSkipQuantModel.forward": [], "common_quantization.AnnotatedSkipQuantModel.fuse_modules": [], "common_quantization.QuantStubModel.__init__": ["torch.quantization.get_default_qconfig", "torch.quantization.DeQuantStub", "torch.quantization.QuantStub", "<builtin>.super", "torch.nn.Linear"], "common_quantization.QuantStubModel.forward": [], "common_quantization.ManualLinearQATModel.__init__": ["torch.quantization.DeQuantStub", "torch.quantization.QuantStub", "<builtin>.super", "torch.nn.Linear", "torch.quantization.get_default_qat_qconfig"], "common_quantization.ManualLinearQATModel.forward": [], "common_quantization.ManualConvLinearQATModel.__init__": ["torch.quantization.DeQuantStub", "torch.quantization.QuantStub", "<builtin>.super", "torch.nn.Linear", "torch.nn.Conv2d", "torch.quantization.get_default_qat_qconfig"], "common_quantization.ManualConvLinearQATModel.forward": [], "common_quantization.SubModelForFusion.__init__": ["torch.nn.Conv2d", "torch.nn.BatchNorm2d", "<builtin>.super"], "common_quantization.SubModelForFusion.forward": [], "common_quantization.SubModelWithoutFusion.__init__": ["torch.nn.ReLU", "torch.nn.Conv2d", "<builtin>.super"], "common_quantization.SubModelWithoutFusion.forward": [], "common_quantization.ModelForFusion.__init__": ["torch.quantization.DeQuantStub", "torch.quantization.QuantStub", "torch.nn.BatchNorm2d", "torch.nn.Conv1d", "common_quantization.SubModelForFusion.__init__", "<builtin>.super", "torch.nn.BatchNorm3d", "torch.nn.BatchNorm1d", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Conv2d", "common_quantization.SubModelWithoutFusion.__init__", "torch.nn.Conv3d"], "torch.nn.Conv3d": [], "torch.nn.BatchNorm3d": [], "torch.nn.Conv1d": [], "torch.nn.BatchNorm1d": [], "common_quantization.ModelForFusion.forward": ["common_quantization.SubModelForFusion.__init__", "torch.nn.Module.unsqueeze", "torch.nn.Module.squeeze", "common_quantization.SubModelWithoutFusion.__init__", "torch.nn.Module.view"], "torch.nn.Module.squeeze": [], "torch.nn.Module.unsqueeze": [], "torch.nn.Module.view": [], "common_quantization.ConvBNReLU.__init__": ["torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "<builtin>.super"], "common_quantization.ModelWithSequentialFusion.__init__": ["torch.quantization.DeQuantStub", "torch.quantization.QuantStub", "<builtin>.range", "torch.nn.Sequential", "<builtin>.super", "common_quantization.ConvBNReLU.__init__", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Conv2d"], "torch.nn.Sequential": [], "common_quantization.ModelWithSequentialFusion.forward": ["torch.reshape"], "torch.reshape": [], "common_quantization.ModelForFusionWithBias.__init__": ["torch.quantization.DeQuantStub", "torch.quantization.QuantStub", "torch.nn.BatchNorm2d", "<builtin>.super", "torch.nn.ReLU", "torch.nn.Conv2d"], "common_quantization.ModelForFusionWithBias.forward": [], "common_quantization.ModelForLinearBNFusion.__init__": ["torch.nn.Linear", "torch.nn.BatchNorm1d", "torch.nn.init.uniform_", "<builtin>.super"], "torch.nn.init.uniform_": [], "common_quantization.ModelForLinearBNFusion.forward": [], "common_quantization.DummyObserver.calculate_qparams": [], "common_quantization.DummyObserver.forward": [], "common_quantization.ModelWithFunctionals.__init__": ["torch.nn.quantized.FloatFunctional", "<builtin>.super"], "torch.nn.quantized.FloatFunctional": [], "common_quantization.ModelWithFunctionals.forward": [], "common_quantization.ResNetBase.__init__": ["torch.nn.BatchNorm2d", "<builtin>.super", "torch.nn.AdaptiveAvgPool2d", "torch.nn.quantized.FloatFunctional", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.Identity"], "torch.nn.Identity": [], "torch.nn.AdaptiveAvgPool2d": [], "common_quantization.ResNetBase.forward": ["torch.flatten"], "torch.flatten": [], "common_quantization.ResNetBase.fuse_model": ["torch.quantization.fuse_modules"], "common_quantization.ModelMultipleOps.__init__": ["torch.nn.BatchNorm2d", "<builtin>.super", "torch.nn.AdaptiveAvgPool2d", "torch.nn.quantized.FloatFunctional", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.Identity"], "common_quantization.ModelMultipleOps.forward": ["torch.nn.functional.max_pool2d"], "torch.nn.functional.max_pool2d": [], "common_quantization.ModelMultipleOpsNoAvgPool.__init__": ["torch.nn.BatchNorm2d", "<builtin>.super", "torch.nn.quantized.FloatFunctional", "torch.nn.Linear", "torch.nn.MaxPool2d", "torch.nn.ReLU", "torch.nn.Conv2d"], "torch.nn.MaxPool2d": [], "common_quantization.ModelMultipleOpsNoAvgPool.forward": ["torch.nn.functional.max_pool2d"], "common_quantization.EmbeddingBagModule.__init__": ["torch.nn.EmbeddingBag", "<builtin>.super"], "common_quantization.EmbeddingBagModule.forward": [], "common_quantization.EmbeddingModule.__init__": ["torch.nn.Embedding", "<builtin>.super"], "common_quantization.EmbeddingModule.forward": [], "common_quantization.EmbeddingWithLinear.__init__": ["torch.nn.Linear", "torch.nn.Embedding", "<builtin>.super"], "common_quantization.EmbeddingWithLinear.forward": [], "common_quantization.DenseTopMLP.__init__": ["torch.nn.Linear", "torch.nn.Sequential", "<builtin>.super"], "common_quantization.DenseTopMLP.forward": ["torch.cat"], "torch.cat": [], "common_quantization.EmbBagWrapper.__init__": ["torch.nn.EmbeddingBag", "<builtin>.super"], "common_quantization.EmbBagWrapper.forward": [], "common_quantization.SparseNNModel.__init__": ["common_quantization.DenseTopMLP.__init__", "common_quantization.EmbBagWrapper.__init__", "<builtin>.super"], "common_quantization.SparseNNModel.forward": ["common_quantization.DenseTopMLP.__init__", "common_quantization.EmbBagWrapper.__init__"]}