{"linear": [], "linear.Linear.__init__": ["<builtin>.super"], "<builtin>.super": [], "linear.Linear.forward": ["<builtin>.RuntimeError", "torch.ops.quantized.linear_dynamic", "torch.ops.quantized.linear_dynamic_fp16"], "torch.ops.quantized.linear_dynamic": [], "torch.ops.quantized.linear_dynamic_fp16": [], "<builtin>.RuntimeError": [], "linear.Linear._get_name": [], "linear.Linear.extra_repr": ["torch.nn.quantized.Linear.weight"], "torch.nn.quantized.Linear.weight": [], "linear.Linear._load_from_state_dict": ["<builtin>.super"], "linear.Linear.from_float": ["<builtin>.hasattr", "torch.nn.quantized.Linear.set_weight_bias", "<builtin>.str", "torch.nn.quantized.modules.utils._quantize_weight", "<builtin>.RuntimeError", "torch.quantization.qconfig.default_dynamic_qconfig.weight", "linear.Linear.__init__", "<builtin>.type"], "<builtin>.type": [], "<builtin>.str": [], "<builtin>.hasattr": [], "torch.quantization.qconfig.default_dynamic_qconfig.weight": [], "torch.nn.quantized.modules.utils._quantize_weight": [], "torch.nn.quantized.Linear.set_weight_bias": []}