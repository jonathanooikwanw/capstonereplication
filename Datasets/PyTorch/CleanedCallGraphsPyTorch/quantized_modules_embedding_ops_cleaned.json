{"embedding_ops": [], "embedding_ops.EmbeddingPackedParams.__init__": ["<builtin>.NotImplementedError", "<builtin>.super", "torch.ones", "torch._empty_per_channel_affine_quantized", "embedding_ops.EmbeddingPackedParams.set_weight", "torch.zeros"], "<builtin>.super": [], "torch.ones": [], "torch.zeros": [], "torch._empty_per_channel_affine_quantized": [], "embedding_ops.EmbeddingPackedParams.set_weight": ["<builtin>.NotImplementedError", "torch.ops.quantized.embedding_bag_prepack"], "<builtin>.NotImplementedError": [], "embedding_ops.EmbeddingPackedParams": ["torch.jit.export"], "torch.jit.export": [], "torch.ops.quantized.embedding_bag_prepack": [], "embedding_ops.EmbeddingPackedParams._weight": ["<builtin>.NotImplementedError", "torch.ops.quantized.embedding_bag_unpack"], "torch.ops.quantized.embedding_bag_unpack": [], "embedding_ops.EmbeddingPackedParams.forward": [], "embedding_ops.EmbeddingPackedParams._save_to_state_dict": ["<builtin>.super", "embedding_ops.EmbeddingPackedParams._weight"], "embedding_ops.EmbeddingPackedParams._load_from_state_dict": ["embedding_ops.EmbeddingPackedParams.set_weight", "<builtin>.super"], "embedding_ops.EmbeddingPackedParams.__repr__": ["embedding_ops.EmbeddingPackedParams._weight"], "embedding_ops.Embedding.__init__": ["<builtin>.list", "<builtin>.super", "torch.ones", "torch._empty_per_channel_affine_quantized", "embedding_ops.EmbeddingPackedParams.set_weight", "embedding_ops.EmbeddingPackedParams.__init__", "torch.zeros"], "<builtin>.list": [], "embedding_ops.Embedding.forward": ["torch.ops.quantized.embedding_byte"], "torch.ops.quantized.embedding_byte": [], "embedding_ops.Embedding._get_name": [], "embedding_ops.Embedding.__repr__": ["torch.nn.quantized.modules.utils.hide_packed_params_repr"], "torch.nn.quantized.modules.utils.hide_packed_params_repr": [], "embedding_ops.Embedding.extra_repr": ["embedding_ops.Embedding.weight"], "embedding_ops.Embedding.weight": ["embedding_ops.EmbeddingPackedParams._weight"], "embedding_ops.Embedding.set_weight": ["embedding_ops.EmbeddingPackedParams.set_weight"], "embedding_ops.Embedding.from_float": ["torch.quantization.float_qparams_weight_only_qconfig.weight", "<builtin>.type", "embedding_ops.Embedding.__init__", "torch.nn.quantized.modules.utils._quantize_weight", "embedding_ops.Embedding.set_weight", "<builtin>.hasattr"], "<builtin>.type": [], "<builtin>.hasattr": [], "torch.quantization.float_qparams_weight_only_qconfig.weight": [], "torch.nn.quantized.modules.utils._quantize_weight": [], "embedding_ops.EmbeddingBag.__init__": ["<builtin>.super"], "embedding_ops.EmbeddingBag.forward": ["torch.ops.quantized.embedding_bag_4bit", "torch.ops.quantized.embedding_bag_byte"], "torch.ops.quantized.embedding_bag_4bit": [], "torch.ops.quantized.embedding_bag_byte": [], "embedding_ops.EmbeddingBag._get_name": [], "embedding_ops.EmbeddingBag.from_float": ["embedding_ops.EmbeddingBag.__init__", "<builtin>.type", "torch.quantization.qconfig.float_qparams_weight_only_qconfig.weight", "torch.nn.quantized.modules.utils._quantize_weight", "embedding_ops.Embedding.set_weight", "<builtin>.hasattr"], "torch.quantization.qconfig.float_qparams_weight_only_qconfig.weight": []}