{"functional_adamax": [], "functional_adamax._FunctionalAdamax.__init__": ["<builtin>.ValueError", "torch.jit.annotate", "<builtin>.len"], "<builtin>.ValueError": [], "torch.jit.annotate": [], "<builtin>.len": [], "functional_adamax._FunctionalAdamax.step": ["torch.optim._functional.adamax", "torch.no_grad", "torch.tensor", "<builtin>.ValueError", "<builtin>.len", "torch.zeros_like", "<builtin>.zip"], "<builtin>.zip": [], "torch.tensor": [], "torch.zeros_like": [], "torch.no_grad": [], "torch.optim._functional.adamax": []}