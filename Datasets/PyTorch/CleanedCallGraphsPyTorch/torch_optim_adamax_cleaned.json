{"adamax": [], "adamax.Adamax.__init__": ["<builtin>.ValueError", "<builtin>.super", "<builtin>.dict"], "<builtin>.ValueError": [], "<builtin>.dict": [], "<builtin>.super": [], "torch.no_grad": [], "adamax.Adamax": ["torch.no_grad"], "adamax.Adamax.step": ["<builtin>.len", "torch.zeros_like", "<builtin>.RuntimeError", "_functional.adamax", "torch.enable_grad"], "torch.enable_grad": [], "<builtin>.RuntimeError": [], "<builtin>.len": [], "torch.zeros_like": [], "_functional.adamax": []}