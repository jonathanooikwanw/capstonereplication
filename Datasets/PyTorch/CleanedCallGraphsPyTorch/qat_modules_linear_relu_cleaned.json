{"linear_relu": [], "linear_relu.LinearReLU.__init__": ["<builtin>.super"], "<builtin>.super": [], "linear_relu.LinearReLU.forward": ["torch.nn.functional.linear", "torch.nn.qat.Linear.weight_fake_quant", "torch.nn.functional.relu"], "torch.nn.qat.Linear.weight_fake_quant": [], "torch.nn.functional.linear": [], "torch.nn.functional.relu": [], "linear_relu.LinearReLU.from_float": ["<builtin>.super"], "linear_relu.LinearReLU.to_float": ["torch.nn.Parameter", "torch.nn.intrinsic.LinearReLU", "torch.nn.ReLU", "torch.nn.qat.Linear.bias.detach", "torch.nn.Linear", "torch.nn.qat.Linear.weight.detach"], "torch.nn.Linear": [], "torch.nn.qat.Linear.weight.detach": [], "torch.nn.Parameter": [], "torch.nn.qat.Linear.bias.detach": [], "torch.nn.ReLU": [], "torch.nn.intrinsic.LinearReLU": []}