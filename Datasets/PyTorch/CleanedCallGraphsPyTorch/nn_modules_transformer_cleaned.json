{"transformer": [], "transformer.Transformer.__init__": ["normalization.LayerNorm", "transformer.TransformerDecoderLayer.__init__", "transformer.TransformerDecoder.__init__", "<builtin>.super", "transformer.TransformerEncoderLayer.__init__", "transformer.Transformer._reset_parameters", "transformer.TransformerEncoder.__init__"], "<builtin>.super": [], "transformer.TransformerEncoderLayer.__init__": ["dropout.Dropout", "normalization.LayerNorm", "linear.Linear", "<builtin>.super", "transformer._get_activation_fn", "activation.MultiheadAttention", "<builtin>.isinstance"], "normalization.LayerNorm": [], "transformer.TransformerEncoder.__init__": ["transformer._get_clones", "<builtin>.super"], "transformer.TransformerDecoderLayer.__init__": ["dropout.Dropout", "normalization.LayerNorm", "linear.Linear", "<builtin>.super", "transformer._get_activation_fn", "activation.MultiheadAttention", "<builtin>.isinstance"], "transformer.TransformerDecoder.__init__": ["transformer._get_clones", "<builtin>.super"], "transformer.Transformer._reset_parameters": ["module.Module.parameters", "init.xavier_uniform_"], "transformer.Transformer.forward": ["transformer.TransformerDecoder.__init__", "<builtin>.RuntimeError", "transformer.TransformerEncoder.__init__"], "<builtin>.RuntimeError": [], "transformer.Transformer.generate_square_subsequent_mask": ["<builtin>.float", "torch.full", "torch.triu"], "<builtin>.float": [], "torch.full": [], "torch.triu": [], "module.Module.parameters": [], "init.xavier_uniform_": [], "transformer._get_clones": ["container.ModuleList", "copy.deepcopy", "<builtin>.range"], "transformer.TransformerEncoder.forward": [], "transformer.TransformerDecoder.forward": [], "activation.MultiheadAttention": [], "linear.Linear": [], "dropout.Dropout": [], "<builtin>.isinstance": [], "transformer._get_activation_fn": ["<builtin>.RuntimeError"], "transformer.TransformerEncoderLayer.__setstate__": ["<builtin>.super"], "transformer.TransformerEncoderLayer.forward": ["transformer.TransformerEncoderLayer._ff_block", "transformer.TransformerEncoderLayer._sa_block"], "transformer.TransformerEncoderLayer._sa_block": [], "transformer.TransformerEncoderLayer._ff_block": ["functional.gelu", "functional.relu"], "functional.gelu": [], "functional.relu": [], "transformer.TransformerDecoderLayer.__setstate__": ["<builtin>.super"], "transformer.TransformerDecoderLayer.forward": ["transformer.TransformerDecoderLayer._sa_block", "transformer.TransformerDecoderLayer._ff_block", "transformer.TransformerDecoderLayer._mha_block"], "transformer.TransformerDecoderLayer._sa_block": [], "transformer.TransformerDecoderLayer._mha_block": [], "transformer.TransformerDecoderLayer._ff_block": ["functional.gelu", "functional.relu"], "copy.deepcopy": [], "<builtin>.range": [], "container.ModuleList": []}