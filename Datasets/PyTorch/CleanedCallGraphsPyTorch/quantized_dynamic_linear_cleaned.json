{"linear": [], "linear.Linear.__init__": ["torch.zeros", "torch.ao.nn.sparse.quantized.linear.LinearPackedParams", "<builtin>.super", "torch._empty_affine_quantized", "<builtin>.NotImplementedError"], "<builtin>.super": [], "<builtin>.NotImplementedError": [], "torch.zeros": [], "torch._empty_affine_quantized": [], "torch.ao.nn.sparse.quantized.linear.LinearPackedParams": [], "linear.Linear._get_name": [], "linear.Linear.extra_repr": ["linear.Linear.weight"], "linear.Linear.weight": ["linear.Linear._weight_bias"], "linear.Linear.__repr__": ["torch.nn.quantized.modules.utils.hide_packed_params_repr"], "torch.nn.quantized.modules.utils.hide_packed_params_repr": [], "linear.Linear.forward": ["torch.ops.sparse.qlinear_dynamic"], "torch.ops.sparse.qlinear_dynamic": [], "linear.Linear._save_to_state_dict": ["<builtin>.super"], "linear.Linear._load_from_state_dict": ["<builtin>.int", "<builtin>.super"], "<builtin>.int": [], "linear.Linear._weight_bias": [], "linear.Linear.bias": ["linear.Linear._weight_bias"], "linear.Linear.set_weight_bias": [], "linear.Linear.from_float": ["torch.ao.nn.sparse.quantized.utils.LinearBlockSparsePattern.block_size", "<builtin>.type", "<builtin>.getattr", "torch.quantization.qconfig.default_dynamic_qconfig.weight", "torch.nn.quantized.modules.utils._quantize_weight", "<builtin>.isinstance", "torch.any", "linear.Linear.__init__", "<builtin>.hasattr"], "<builtin>.type": [], "<builtin>.hasattr": [], "torch.quantization.qconfig.default_dynamic_qconfig.weight": [], "<builtin>.getattr": [], "<builtin>.isinstance": [], "torch.any": [], "torch.nn.quantized.modules.utils._quantize_weight": [], "torch.ao.nn.sparse.quantized.utils.LinearBlockSparsePattern.block_size": []}