{"seq2seq_util": [], "seq2seq_util.gen_vocab": ["collections.defaultdict", "<builtin>.open", "future.utils.viewitems"], "seq2seq_util.gen_vocab.<lambda1>": ["<builtin>.len"], "<builtin>.len": [], "collections.defaultdict": [], "seq2seq_util.gen_vocab.<lambda2>": [], "<builtin>.open": [], "future.utils.viewitems": [], "seq2seq_util.get_numberized_sentence": [], "seq2seq_util.rnn_unidirectional_layer": ["caffe2.python.rnn_cell.LSTMCell", "caffe2.python.core.NameScope", "caffe2.python.rnn_cell.DropoutCell"], "caffe2.python.core.NameScope": [], "caffe2.python.rnn_cell.LSTMCell": [], "caffe2.python.rnn_cell.DropoutCell": [], "seq2seq_util.rnn_bidirectional_layer": ["seq2seq_util.rnn_unidirectional_layer", "caffe2.python.core.NameScope"], "seq2seq_util.build_embeddings": [], "seq2seq_util.get_layer_scope": [], "seq2seq_util.build_embedding_encoder": ["<builtin>.len", "seq2seq_util.rnn_unidirectional_layer", "<builtin>.enumerate", "caffe2.python.core.DeviceScope", "caffe2.python.core.DeviceOption", "caffe2.python.core.NameScope", "seq2seq_util.get_layer_scope", "seq2seq_util.rnn_bidirectional_layer"], "caffe2.python.core.DeviceOption": [], "caffe2.python.core.DeviceScope": [], "<builtin>.enumerate": [], "seq2seq_util.LSTMWithAttentionDecoder.scope": [], "seq2seq_util.LSTMWithAttentionDecoder._get_attention_type": [], "seq2seq_util.LSTMWithAttentionDecoder.__init__": ["<builtin>.len", "caffe2.python.rnn_cell.MultiRNNCell", "caffe2.python.rnn_cell.AttentionCell", "seq2seq_util.LSTMWithAttentionDecoder.scope", "seq2seq_util.LSTMWithAttentionDecoder._get_attention_type"], "caffe2.python.rnn_cell.MultiRNNCell": [], "caffe2.python.rnn_cell.AttentionCell": [], "seq2seq_util.LSTMWithAttentionDecoder.get_state_names": [], "seq2seq_util.LSTMWithAttentionDecoder.get_outputs_with_grads": [], "seq2seq_util.LSTMWithAttentionDecoder.get_output_dim": [], "seq2seq_util.LSTMWithAttentionDecoder.get_attention_weights": [], "seq2seq_util.LSTMWithAttentionDecoder.apply": [], "seq2seq_util.LSTMWithAttentionDecoder.apply_over_sequence": ["seq2seq_util.LSTMWithAttentionDecoder.get_outputs_with_grads"], "seq2seq_util.build_initial_rnn_decoder_states": ["<builtin>.len", "caffe2.python.brew.fc", "<builtin>.enumerate"], "caffe2.python.brew.fc": [], "seq2seq_util.build_embedding_decoder": ["seq2seq_util.build_initial_rnn_decoder_states", "seq2seq_util.LSTMWithAttentionDecoder.__init__", "seq2seq_util.LSTMWithAttentionDecoder.get_output_dim", "<builtin>.enumerate", "caffe2.python.rnn_cell.LSTMCell", "caffe2.python.core.DeviceScope", "caffe2.python.rnn_cell.DropoutCell", "caffe2.python.core.DeviceOption", "caffe2.python.core.NameScope", "seq2seq_util.LSTMWithAttentionDecoder.apply_over_sequence", "seq2seq_util.get_layer_scope"], "seq2seq_util.output_projection": ["caffe2.python.brew.fc"]}