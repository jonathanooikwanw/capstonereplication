{"gradcheck": [], "gradcheck._is_float_or_complex_tensor": ["torch.overrides.is_tensor_like"], "torch.overrides.is_tensor_like": [], "gradcheck._allocate_jacobians_with_inputs": ["<builtin>.tuple", "gradcheck._is_float_or_complex_tensor"], "<builtin>.tuple": [], "gradcheck._allocate_jacobians_with_outputs": ["<builtin>.tuple", "gradcheck._is_float_or_complex_tensor"], "gradcheck._iter_tensors": ["<builtin>.isinstance", "torch.overrides.is_tensor_like", "gradcheck._iter_tensors"], "<builtin>.isinstance": [], "gradcheck._iter_tensor": ["<builtin>.range", "<builtin>.list", "<builtin>.len", "itertools.product", "<builtin>.enumerate", "<builtin>.sum", "gradcheck._iter_tensor.get_stride"], "gradcheck._iter_tensor.get_stride": ["<builtin>.reversed", "<builtin>.len", "<builtin>.range"], "<builtin>.len": [], "<builtin>.range": [], "<builtin>.reversed": [], "<builtin>.list": [], "itertools.product": [], "<builtin>.sum": [], "<builtin>.enumerate": [], "gradcheck._get_numerical_jacobian": ["gradcheck.get_numerical_jacobian_wrt_specific_input", "<builtin>.ValueError", "torch.overrides.is_tensor_like", "<builtin>.any", "<builtin>.zip", "gradcheck.get_numerical_jacobian.fn_pack_inps", "gradcheck._as_tuple", "<builtin>.enumerate", "gradcheck._iter_tensors"], "gradcheck._as_tuple": ["<builtin>.isinstance", "<builtin>.tuple"], "gradcheck.get_numerical_jacobian.fn_pack_inps": [], "<builtin>.any": [], "<builtin>.ValueError": [], "<builtin>.zip": [], "gradcheck.get_numerical_jacobian_wrt_specific_input": ["gradcheck._combine_jacobian_cols", "gradcheck._get_numerical_jvp_fn", "functools.partial", "gradcheck._compute_numerical_jvps_wrt_specific_input", "gradcheck._with_prepare_inputs", "gradcheck._iter_tensor"], "gradcheck.get_numerical_jacobian": ["gradcheck._get_numerical_jacobian", "<builtin>.tuple", "<builtin>.ValueError", "warnings.warn"], "warnings.warn": [], "gradcheck._compute_numerical_gradient": ["<builtin>.tuple", "gradcheck._compute_numerical_gradient.compute", "gradcheck._with_prepare_inputs.wrapped_fn", "<builtin>.zip"], "gradcheck._with_prepare_inputs.wrapped_fn": ["<builtin>.tuple", "torch.overrides.is_tensor_like", "gradcheck._prepare_input", "gradcheck._as_tuple", "gradcheck.get_numerical_jacobian.fn_pack_inps", "<builtin>.enumerate"], "gradcheck._compute_numerical_gradient.compute": [], "gradcheck._compute_numerical_jvps_wrt_specific_input": ["<builtin>.isinstance", "gradcheck._get_numerical_jvp_fn.jvp_fn", "<builtin>.zip"], "gradcheck._get_numerical_jvp_fn.jvp_fn": ["gradcheck._compute_numerical_gradient"], "gradcheck._combine_jacobian_cols": ["gradcheck._allocate_jacobians_with_outputs", "<builtin>.enumerate"], "gradcheck._prepare_input": [], "gradcheck.check_outputs_same_dtype_and_shape": [], "gradcheck._with_prepare_inputs": [], "functools.partial": [], "gradcheck._get_numerical_jvp_fn": [], "gradcheck._get_analytical_jacobian_forward_ad": ["torch.autograd.forward_ad.make_dual", "<builtin>.tuple", "<builtin>.ValueError", "<builtin>.range", "torch.autograd.forward_ad.dual_level", "gradcheck._allocate_jacobians_with_outputs", "<builtin>.filter", "torch.overrides.is_tensor_like", "<builtin>.any", "gradcheck._as_tuple", "<builtin>.zip", "torch.zeros_like", "itertools.product", "torch.autograd.forward_ad.unpack_dual", "<builtin>.enumerate", "gradcheck._run_slow_mode_and_get_error.new_fn"], "torch.autograd.forward_ad.dual_level": [], "torch.zeros_like": [], "torch.autograd.forward_ad.make_dual": [], "torch.autograd.forward_ad.unpack_dual": [], "gradcheck._run_slow_mode_and_get_error.new_fn": ["<builtin>.list", "gradcheck._as_tuple"], "<builtin>.filter": [], "gradcheck._get_input_to_perturb": [], "gradcheck._reshape_tensor_or_tuple": ["<builtin>.isinstance"], "gradcheck._mul_tensor_or_tuple": ["<builtin>.isinstance"], "gradcheck._get_numerical_jvp_wrt_specific_input": ["gradcheck._get_numerical_jvp_fn", "functools.partial", "gradcheck._get_input_to_perturb", "gradcheck._reshape_tensor_or_tuple", "gradcheck._compute_numerical_jvps_wrt_specific_input", "gradcheck._mul_tensor_or_tuple", "gradcheck._with_prepare_inputs"], "gradcheck._get_numerical_vJu": ["gradcheck._dot_with_type_promotion", "gradcheck._get_numerical_jvp_wrt_specific_input", "gradcheck._is_float_or_complex_tensor", "<builtin>.len", "gradcheck._as_tuple", "<builtin>.zip", "<builtin>.enumerate"], "gradcheck._dot_with_type_promotion": [], "gradcheck._check_jacobians_equal": ["<builtin>.zip"], "gradcheck._stack_and_check_tensors": ["gradcheck._allocate_jacobians_with_inputs", "<builtin>.list", "<builtin>.enumerate", "gradcheck._iter_tensors"], "gradcheck._check_analytical_jacobian_attributes": ["gradcheck._stack_and_check_tensors", "<builtin>.list", "gradcheck._compute_analytical_jacobian_rows", "gradcheck._get_analytical_vjps_wrt_specific_output", "gradcheck._iter_tensors", "gradcheck._check_jacobians_equal"], "gradcheck._check_analytical_jacobian_attributes.vjp_fn": ["torch.autograd.grad"], "torch.autograd.grad": [], "gradcheck._get_analytical_vjps_wrt_specific_output": ["gradcheck._check_analytical_jacobian_attributes.vjp_fn"], "gradcheck._compute_analytical_jacobian_rows": ["gradcheck._check_analytical_jacobian_attributes.vjp_fn", "<builtin>.range", "gradcheck.get_analytical_jacobian.vjp_fn", "torch.zeros_like", "<builtin>.enumerate"], "gradcheck._get_analytical_vJu_backward_mode": ["gradcheck._check_analytical_jacobian_attributes", "torch.view_as_real", "<builtin>.zip"], "torch.view_as_real": [], "gradcheck.get_analytical_jacobian": ["<builtin>.ValueError", "gradcheck._stack_and_check_tensors", "warnings.warn", "<builtin>.list", "gradcheck._compute_analytical_jacobian_rows", "gradcheck._iter_tensors", "gradcheck._check_jacobians_equal"], "gradcheck.get_analytical_jacobian.vjp_fn": ["torch.autograd.grad"], "gradcheck._get_analytical_jacobian": ["gradcheck._check_analytical_jacobian_attributes", "<builtin>.float"], "<builtin>.float": [], "gradcheck._check_inputs": ["<builtin>.all", "<builtin>.ValueError", "<builtin>.RuntimeError", "<builtin>.isinstance", "torch.overrides.is_tensor_like", "warnings.warn", "<builtin>.any", "<builtin>.zip", "<builtin>.enumerate"], "<builtin>.all": [], "<builtin>.RuntimeError": [], "gradcheck._check_outputs": ["<builtin>.isinstance", "<builtin>.ValueError", "<builtin>.any"], "gradcheck._check_no_differentiable_outputs": ["gradcheck._get_numerical_jacobian", "torch.ne"], "torch.ne": [], "gradcheck._check_no_differentiable_outputs_fast": ["torch.zeros_like", "gradcheck._get_numerical_jvp_wrt_specific_input", "<builtin>.zip"], "gradcheck._get_failed_batched_grad_test_msg": [], "gradcheck._test_batched_grad": ["torch.allclose", "functools.partial", "<builtin>.range", "torch.stack", "warnings.filterwarnings", "torch._vmap_internals.vmap", "<builtin>.list", "<builtin>.enumerate", "torch.randn_like", "gradcheck._test_batched_grad.vjp", "<builtin>.zip", "gradcheck._get_failed_batched_grad_test_msg", "warnings.catch_warnings", "gradcheck._iter_tensors"], "gradcheck._test_batched_grad.vjp": ["<builtin>.tuple", "torch.zeros", "<builtin>.zip"], "torch.zeros": [], "torch.randn_like": [], "torch.stack": [], "warnings.catch_warnings": [], "warnings.filterwarnings": [], "torch._vmap_internals.vmap": [], "torch.allclose": [], "gradcheck._test_backward_mul_by_grad_output": ["torch.allclose", "<builtin>.isinstance", "<builtin>.list", "<builtin>.str", "torch.autograd.grad", "<builtin>.zip", "torch.zeros_like", "gradcheck._iter_tensors"], "<builtin>.str": [], "gradcheck._test_undefined_grad": ["gradcheck._test_undefined_grad.check_undefined_grad_support", "<builtin>.all", "<builtin>.range", "<builtin>.isinstance", "gradcheck._differentiable_outputs", "<builtin>.list", "<builtin>.len", "torch._C._functions.UndefinedGrad", "<builtin>.enumerate", "gradcheck._iter_tensors"], "gradcheck._test_undefined_grad.warn_bc_breaking": ["warnings.warn"], "gradcheck._test_undefined_grad.check_undefined_grad_support": ["torch.zeros_like", "<builtin>.zip", "gradcheck._test_undefined_grad.warn_bc_breaking", "torch.autograd.grad"], "torch._C._functions.UndefinedGrad": [], "gradcheck._differentiable_outputs": ["<builtin>.tuple", "gradcheck._as_tuple"], "gradcheck._get_notallclose_msg": [], "gradcheck._transpose": ["<builtin>.list", "<builtin>.zip"], "gradcheck._real_and_imag_output": ["gradcheck._real_and_imag_output.apply_to_c_outs"], "gradcheck._real_and_imag_output.apply_to_c_outs": [], "gradcheck._real_and_imag_output.apply_to_c_outs.wrapped_fn": ["<builtin>.tuple", "torch.real", "torch.imag", "gradcheck._as_tuple"], "torch.imag": [], "torch.real": [], "gradcheck._real_and_imag_input": ["gradcheck._real_and_imag_input.apply_to_c_inps"], "gradcheck._real_and_imag_input.apply_to_c_inps": [], "gradcheck._real_and_imag_input.apply_to_c_inps.wrapped_fn": ["gradcheck._as_tuple", "<builtin>.list", "gradcheck._real_and_imag_input.<lambda2>", "gradcheck._real_and_imag_input.<lambda1>"], "gradcheck._real_and_imag_input.<lambda1>": [], "gradcheck._real_and_imag_input.<lambda2>": [], "gradcheck._gradcheck_real_imag": ["gradcheck._real_and_imag_output", "torch.overrides.is_tensor_like", "<builtin>.any", "gradcheck._differentiable_outputs", "gradcheck._real_and_imag_input", "gradcheck._as_tuple", "<builtin>.enumerate"], "gradcheck._slow_gradcheck": ["gradcheck._get_numerical_jacobian", "gradcheck._get_notallclose_msg", "gradcheck._check_analytical_jacobian_attributes", "gradcheck._transpose", "<builtin>.zip", "gradcheck._get_analytical_jacobian_forward_ad", "gradcheck._allclose_with_type_promotion", "gradcheck._as_tuple", "gradcheck._check_no_differentiable_outputs", "<builtin>.enumerate"], "gradcheck._allclose_with_type_promotion": ["torch.promote_types", "torch.allclose"], "torch.promote_types": [], "gradcheck._to_real_dtype": [], "gradcheck._vec_from_tensor": ["torch.rand", "gradcheck._to_real_dtype", "torch.sparse_coo_tensor"], "torch.rand": [], "torch.sparse_coo_tensor": [], "gradcheck._get_inp_tensors": ["<builtin>.enumerate", "torch.overrides.is_tensor_like"], "gradcheck._adjusted_atol": ["<builtin>.isinstance", "<builtin>.float", "torch.sparse.sum"], "torch.sparse.sum": [], "gradcheck._run_slow_mode_and_get_error": ["gradcheck._get_analytical_jacobian", "gradcheck._get_numerical_jacobian", "torch.allclose", "gradcheck._get_analytical_jacobian_forward_ad"], "gradcheck._to_flat_dense_if_sparse": [], "gradcheck._make_vectors": ["gradcheck._to_flat_dense_if_sparse", "torch.Generator", "gradcheck._vec_from_tensor"], "torch.Generator": [], "gradcheck._check_analytical_numerical_equal": ["gradcheck._get_notallclose_msg", "gradcheck._adjusted_atol", "gradcheck._allclose_with_type_promotion", "<builtin>.enumerate", "gradcheck._run_slow_mode_and_get_error"], "gradcheck._fast_gradcheck": ["gradcheck._make_vectors", "gradcheck._check_analytical_numerical_equal", "gradcheck._get_numerical_vJu", "gradcheck._get_analytical_jacobian_forward_ad", "gradcheck._get_analytical_vJu_backward_mode", "gradcheck._as_tuple", "gradcheck._get_inp_tensors", "gradcheck._check_no_differentiable_outputs_fast"], "gradcheck.gradcheck": ["<builtin>.locals", "gradcheck._gradcheck_helper"], "<builtin>.locals": [], "gradcheck._gradcheck_helper": ["gradcheck._gradcheck_real_imag", "gradcheck._check_outputs", "gradcheck._test_batched_grad", "gradcheck._differentiable_outputs", "gradcheck._test_undefined_grad", "gradcheck._as_tuple", "gradcheck._check_inputs", "<builtin>.enumerate", "gradcheck._test_backward_mul_by_grad_output"], "gradcheck.gradgradcheck": ["<builtin>.tuple", "gradcheck.gradgradcheck.randn_like", "<builtin>.len", "gradcheck._as_tuple", "gradcheck.gradcheck"], "gradcheck.gradgradcheck.randn_like": ["torch.testing.make_non_contiguous", "torch.randn_like"], "torch.testing.make_non_contiguous": [], "gradcheck.gradgradcheck.new_func": ["gradcheck._differentiable_outputs", "<builtin>.tuple", "torch.overrides.is_tensor_like", "torch.autograd.grad"]}