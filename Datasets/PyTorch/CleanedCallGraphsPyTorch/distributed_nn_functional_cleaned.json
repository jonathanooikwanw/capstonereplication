{"functional": [], "functional.broadcast": ["torch.autograd.Function.apply"], "torch.autograd.Function.apply": [], "functional.gather": ["torch.autograd.Function.apply"], "functional.scatter": ["torch.autograd.Function.apply"], "functional.reduce": ["torch.autograd.Function.apply"], "functional.all_gather": ["torch.autograd.Function.apply"], "functional.all_to_all": ["torch.autograd.Function.apply"], "functional.all_reduce": ["torch.autograd.Function.apply"], "functional._Broadcast.forward": ["torch.distributed.broadcast", "torch.distributed.get_rank"], "torch.distributed.get_rank": [], "torch.distributed.broadcast": [], "functional._Broadcast.backward": ["torch.autograd.Function.apply"], "functional._Gather.forward": ["torch.distributed.get_world_size", "torch.zeros_like", "<builtin>.tuple", "<builtin>.range", "torch.distributed.gather", "torch.distributed.get_rank"], "torch.zeros_like": [], "torch.distributed.get_world_size": [], "<builtin>.range": [], "torch.distributed.gather": [], "<builtin>.tuple": [], "functional._Gather.backward": ["torch.autograd.Function.apply"], "functional._Scatter.forward": ["<builtin>.list", "torch.distributed.scatter", "torch.zeros_like", "<builtin>.all", "torch.distributed.get_rank"], "<builtin>.all": [], "<builtin>.list": [], "torch.distributed.scatter": [], "functional._Scatter.backward": ["torch.autograd.Function.apply"], "functional._Reduce.forward": ["torch.distributed.reduce"], "torch.distributed.reduce": [], "functional._Reduce.backward": ["torch.autograd.Function.apply"], "functional._AllGather.forward": ["torch.distributed.get_world_size", "<builtin>.tuple", "torch.empty_like", "<builtin>.range", "torch.distributed.all_gather"], "torch.empty_like": [], "torch.distributed.all_gather": [], "functional._AllGather.backward": ["torch.stack", "torch.autograd.Function.apply", "torch.sum"], "torch.stack": [], "torch.sum": [], "functional._AlltoAll.forward": ["torch.distributed.get_world_size", "<builtin>.list", "torch.distributed.scatter", "torch.empty_like", "<builtin>.tuple", "<builtin>.range", "torch.distributed.get_backend", "torch.distributed.all_to_all", "torch.distributed.get_rank"], "torch.distributed.get_backend": [], "torch.distributed.all_to_all": [], "functional._AlltoAll.backward": ["torch.autograd.Function.apply"], "functional._AllReduce.forward": ["torch.distributed.all_reduce"], "torch.distributed.all_reduce": [], "functional._AllReduce.backward": ["torch.autograd.Function.apply"]}