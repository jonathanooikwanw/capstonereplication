{"parallel_apply": [], "parallel_apply.get_a_var": ["<builtin>.isinstance", "<builtin>.map"], "<builtin>.isinstance": [], "<builtin>.map": [], "parallel_apply.parallel_apply": ["torch.is_autocast_enabled", "torch.is_grad_enabled", "threading.Thread", "<builtin>.zip", "<builtin>.enumerate", "threading.Lock", "parallel_apply.parallel_apply._worker", "torch.cuda._utils._get_device_index", "<builtin>.isinstance", "<builtin>.range", "<builtin>.len"], "<builtin>.len": [], "torch.cuda._utils._get_device_index": [], "threading.Lock": [], "torch.is_grad_enabled": [], "torch.is_autocast_enabled": [], "parallel_apply.parallel_apply._worker": ["parallel_apply.get_a_var", "torch.set_grad_enabled", "torch._utils.ExceptionWrapper", "torch.cuda.amp.autocast", "<builtin>.isinstance", "torch.cuda.device"], "torch.set_grad_enabled": [], "torch.cuda.device": [], "torch.cuda.amp.autocast": [], "torch._utils.ExceptionWrapper": [], "threading.Thread": [], "<builtin>.zip": [], "<builtin>.enumerate": [], "<builtin>.range": []}