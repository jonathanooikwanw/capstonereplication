{"adam": [], "adam.Adam.__init__": ["<builtin>.super", "<builtin>.ValueError", "<builtin>.dict"], "<builtin>.ValueError": [], "<builtin>.dict": [], "<builtin>.super": [], "adam.Adam.__setstate__": ["<builtin>.super", "optimizer.Optimizer.param_groups.setdefault"], "optimizer.Optimizer.param_groups.setdefault": [], "torch.no_grad": [], "adam.Adam": ["torch.no_grad"], "adam.Adam.step": ["torch.enable_grad", "torch._foreach_maximum", "torch._foreach_add", "torch._foreach_sqrt", "torch._foreach_add_", "torch._foreach_div_", "torch._foreach_mul_", "torch._foreach_addcdiv_", "math.sqrt", "torch.zeros_like", "torch._foreach_addcmul_", "<builtin>.RuntimeError", "<builtin>.len"], "torch.enable_grad": [], "<builtin>.RuntimeError": [], "<builtin>.len": [], "torch.zeros_like": [], "torch._foreach_add": [], "torch._foreach_mul_": [], "torch._foreach_add_": [], "torch._foreach_addcmul_": [], "torch._foreach_maximum": [], "torch._foreach_sqrt": [], "math.sqrt": [], "torch._foreach_div_": [], "torch._foreach_addcdiv_": [], "adam.Adam.zero_grad": ["collections.defaultdict", "torch._foreach_zero_"], "adam.Adam.zero_grad.<lambda1>": ["collections.defaultdict"], "collections.defaultdict": [], "torch._foreach_zero_": []}